{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dokj3AV9zI6Z"
      },
      "source": [
        "## Tutorial - Seq2Seq model for Neural Machine Translation\n",
        "This tutorial is adapted from [_NLP From Scratch: Translation with a Sequence to Sequence Network and Attention_](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) tutorial from Pytoch documentations.\n",
        "\n",
        "In this tutorial you will learn how to one language to another using neural network. Here, we treanslate English to French as example.\n",
        "\n",
        "```\n",
        "[KEY: > input, = target, < output]\n",
        "\n",
        "> il est en train de peindre un tableau .\n",
        "= he is painting a picture .\n",
        "< he is painting a picture .\n",
        "\n",
        "> pourquoi ne pas essayer ce vin delicieux ?\n",
        "= why not try that delicious wine ?\n",
        "< why not try that delicious wine ?\n",
        "\n",
        "> vous etes trop maigre .\n",
        "= you re too skinny .\n",
        "< you re all alone .\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWU237IjzI6e",
        "outputId": "c778e636-b51a-419e-dcb9-1d58072a617f"
      },
      "outputs": [],
      "source": [
        "#Generic imports and OS settings\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import matplotlib\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fZldjD8hzI6h"
      },
      "outputs": [],
      "source": [
        "## Requirements\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "from tqdm import trange\n",
        "import torch\n",
        "import nltk \n",
        "\n",
        "#Custom imports and device settings\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate import meteor\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSqk3xOzI6i"
      },
      "source": [
        "### Part1 - Seq2Seq model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RxgAt3tYzI6k"
      },
      "source": [
        "Transforming one sequence to another is possible by the simple but powerful idea of the [sequence to sequence network](https://arxiv.org/abs/1409.3215), in which two recurrent neural networks work. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k8pfH3G-zI6l"
      },
      "source": [
        "#### Loading data files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P1qodl52zI6l"
      },
      "source": [
        "The data used in this tutorial contains thousands of English to French translation pairs.\n",
        "\n",
        "This question on Open Data Stack Exchange pointed me to the open translation site https://tatoeba.org/ which has downloads available at https://tatoeba.org/eng/downloads - and better yet, someone did the extra work of splitting language pairs into individual text files here: https://www.manythings.org/anki/\n",
        "\n",
        "The English to French pairs can be found at data/eng-fra.txt. It is a tab separated list of translation pairs.\n",
        "```\n",
        "I am cold.    J'ai froid.\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "usIv7r7NzI6n"
      },
      "source": [
        "We will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). There are many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language.\n",
        "\n",
        "![vocab](https://pytorch.org/tutorials/_images/word-encoding.png)\n",
        "\n",
        "We’ll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called Lang which has word → index (word2index) and index → word (index2word) dictionaries, as well as a count of each word word2count which will be used to replace rare words later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GIF75UoszI6o"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def stoi(self, word):\n",
        "        return self.word2index[word]\n",
        "    \n",
        "    def itos(self, ndx):\n",
        "        return self.index2word[ndx]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhpa39gqzI6q"
      },
      "source": [
        "All files are in Unicode, to simplify, we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bCghv1VyzI6q"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RECIPE DATA PROCESSING\n",
        "\n",
        "Pipeline is: \n",
        "1. process raw text extracts recipe pairs from the raw text folders by calling text-to-recipe\n",
        "2. recipes are cleaned up with data normalisation and preprocessing\n",
        "3. write-tsv writes the tsv objects with the recipe list\n",
        "\n",
        "these TSV files are our new data\n",
        "\n",
        "4. extract pairs pulls the data from the tsv files\n",
        "5. the pairs are passed into build-language as well as into their own object\n",
        "6. pairs and both languages are returned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marks\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "measurements = {\"c\", \"tsp\", \"tbsp\", \"qt\", \"cn\", \"lb\", \"ts\", \"ea\", \"lg\", \"tb\"}\n",
        "stop_words.update(measurements)\n",
        "\n",
        "\n",
        "def trim_stopwords(text):\n",
        "    output = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "    output = output.lower()\n",
        "    return output\n",
        "\n",
        "def recipe_cleanup(all_recipes):\n",
        "    outputs = []\n",
        "    for recipe in all_recipes:\n",
        "        clean_ing = trim_stopwords(recipe[0])\n",
        "        clean_step = trim_stopwords(recipe[1])\n",
        "        outputs.append((clean_ing, clean_step))\n",
        "    return outputs\n",
        "\n",
        "    #     - lower (10 mins)\n",
        "    # - dissolve contractions (30 mins)\n",
        "    # - remove stopwords (20 mins)\n",
        "\n",
        "# test_recipe = trim_stopwords(\"Ours is the Question of Glory\")\n",
        "# print(test_recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_recipe_processing(line):\n",
        "    title = re.findall(r'Title: (.*)', line)\n",
        "    ingredients = re.findall(r'ingredients: (.*)', line)\n",
        "    steps = re.findall(r'ingredients: .*\\n([\\s\\S]*)', line)\n",
        "    try:\n",
        "        title = title[0]\n",
        "        title = re.sub(r'[^a-zA-Z ]', '', title) #remove non-alpha or underscore characters\n",
        "        title = re.sub(r'\\s+', ' ', title) #remove excess spaces\n",
        "        ingredients = ingredients[0].replace('''\\t''', \" \") #replace tab with space for better formatting\n",
        "        ingredients = re.sub(r'[^a-zA-Z ]', '', ingredients)\n",
        "        ingredients = re.sub(r'\\s+', ' ', ingredients)\n",
        "        steps = steps[0].replace('''\\n''', \" \") #replace newline in steps with space\n",
        "        steps = re.sub(r'[^a-zA-Z ]', '', steps)\n",
        "        steps = re.sub(r'\\s+', ' ', steps)\n",
        "    except:\n",
        "        return None\n",
        "    return (str(title + \" \" + ingredients), str(steps))\n",
        "\n",
        "def process_rawtext(path):\n",
        "    print(\"Processing text data from {}\".format(path))\n",
        "    recipes = []\n",
        "    files = glob.glob(path + \"/*.txt\")\n",
        "    for file in files:\n",
        "        lines = open(file, encoding='utf-8').read().strip().split(\"END RECIPE\")\n",
        "        for l in lines:\n",
        "            recipe = text_to_recipe_processing(l)\n",
        "            if recipe is not None:\n",
        "                recipes.append(recipe)\n",
        "    return recipes\n",
        "\n",
        "def write_to_tsv(destination, recipe_list):\n",
        "    with open(destination, 'w',  newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile, delimiter='\\t')\n",
        "        for recipe in recipe_list:\n",
        "            writer.writerow(recipe)\n",
        "\n",
        "def build_language(data_paths):\n",
        "    all_ingredients = []\n",
        "    all_recipes = []\n",
        "    for path in data_paths: #manual path list:\n",
        "        recipes = extract_pairs(path)\n",
        "        for r in recipes:\n",
        "            all_ingredients.append(r[0])\n",
        "            all_recipes.append(r[1])\n",
        "    ingredient_lang = Lang(\"ingredients\")\n",
        "    recipe_lang = Lang(\"recipes\")\n",
        "    for ing in all_ingredients:\n",
        "        ingredient_lang.addSentence(ing)\n",
        "    for rec in all_recipes:\n",
        "        recipe_lang.addSentence(rec)\n",
        "    return ingredient_lang, recipe_lang\n",
        "\n",
        "# def extract_pairs(path):\n",
        "#     all_recipes = []\n",
        "#     file = open(path, 'r')\n",
        "#     lines = file.readlines()\n",
        "#     for l in lines:\n",
        "#         items = [normalizeString(s) for s in l.split(\"\"\"\\t\"\"\")]\n",
        "#         all_recipes.append(items)\n",
        "#     all_recipes = filterPairs(all_recipes)\n",
        "#     return all_recipes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing text data from Cooking_Dataset/test\n"
          ]
        }
      ],
      "source": [
        "### Recipes with stopwords included\n",
        "# train_recipes = process_rawtext(\"Cooking_Dataset/train\")\n",
        "# write_to_tsv(\"Dataset/train.tsv\", train_recipes)\n",
        "# test_recipes = process_rawtext(\"Cooking_Dataset/test\")\n",
        "# write_to_tsv(\"Dataset/test.tsv\", test_recipes)\n",
        "# dev_recipes = process_rawtext(\"Cooking_Dataset/dev\")\n",
        "# write_to_tsv(\"Dataset/dev.tsv\", dev_recipes)\n",
        "\n",
        "###Recipes without stopwords\n",
        "train_recipes = process_rawtext(\"Cooking_Dataset/train\")\n",
        "cleaned_train = recipe_cleanup(train_recipes)\n",
        "write_to_tsv(\"Clean_Data/train.tsv\", cleaned_train)\n",
        "dev_recipes = process_rawtext(\"Cooking_Dataset/dev\")\n",
        "cleaned_dev = recipe_cleanup(dev_recipes)\n",
        "write_to_tsv(\"Clean_Data/dev.tsv\", cleaned_dev)\n",
        "test_recipes = process_rawtext(\"Cooking_Dataset/test\")\n",
        "cleaned_test = recipe_cleanup(test_recipes)\n",
        "write_to_tsv(\"Clean_Data/test.tsv\", cleaned_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKaq7QGzI6r"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split lines into pairs. The used files contain English → Other Language, so I added the `reverse` flag to reverse the pairs, in case that you want to translate from Other Language → English ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fG4twu-pzI6s"
      },
      "outputs": [],
      "source": [
        "# def readLangs(lang1, lang2, reverse=False):\n",
        "#     print(\"Reading lines...\")\n",
        "\n",
        "#     # Read the file and split into lines\n",
        "#     file_name = 'data/%s-%s.txt' % (lang1, lang2)\n",
        "#     lines = open(file_name, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "\n",
        "#     # Split every line into pairs and normalize\n",
        "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "#     # Reverse pairs, make Lang instances\n",
        "#     if reverse:\n",
        "#         pairs = [list(reversed(p)) for p in pairs]\n",
        "#         input_lang = Lang(lang2)\n",
        "#         output_lang = Lang(lang1)\n",
        "#     else:\n",
        "#         input_lang = Lang(lang1)\n",
        "#         output_lang = Lang(lang2)\n",
        "\n",
        "#     return input_lang, output_lang, pairs\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TyAuHpoGzI6s"
      },
      "source": [
        "Pairs can be later extracted from the .tsv files and returned as recipes, after being filtered for passing max length and the strings normalised (just in case any stray data makes it through the cleanup phase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JFBL2updzI6t"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 150 \n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def extract_pairs(path):\n",
        "    all_recipes = []\n",
        "    file = open(path, 'r')\n",
        "    lines = file.readlines()\n",
        "    for l in lines:\n",
        "        items = [normalizeString(s) for s in l.split(\"\"\"\\t\"\"\")]\n",
        "        all_recipes.append(items)\n",
        "    all_recipes = filterPairs(all_recipes)\n",
        "    return all_recipes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DZgHx1ICzI6u"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "- Read text file and split into lines, split lines into pairs\n",
        "- Normalize text, filter by length and content\n",
        "- Make word lists from sentences in pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvic3S4UzI6u",
        "outputId": "4c2fb10f-a4ea-4c6a-b471-b7525b0e821a"
      },
      "outputs": [],
      "source": [
        "# def prepareData(lang1, lang2, reverse=False):\n",
        "#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "#     print(\"Read %s sentence pairs\" % len(pairs))\n",
        "#     pairs = filterPairs(pairs)\n",
        "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "#     print(\"Counting words...\")\n",
        "#     for pair in pairs:\n",
        "#         input_lang.addSentence(pair[0])\n",
        "#         output_lang.addSentence(pair[1])\n",
        "#     print(\"Counted words:\")\n",
        "#     print(input_lang.name, input_lang.n_words)\n",
        "#     print(output_lang.name, output_lang.n_words)\n",
        "#     return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "# input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "# print(random.choice(pairs))\n",
        "dataset_path = [\"Dataset/train.tsv\", \"Dataset/dev.tsv\", \"Dataset/test.tsv\"]\n",
        "input_lang, output_lang = build_language(dataset_path)\n",
        "pairs = extract_pairs(\"Dataset/train.tsv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "imdZM1z3zI6v"
      },
      "source": [
        "### MODEL DEFINITION - MODEL ONE\n",
        "A Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
        "\n",
        "A Sequence to Sequence network, or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFHCitqzI6v"
      },
      "source": [
        "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.\n",
        "\n",
        "Consider the sentence “Je ne suis pas le chat noir” → “I am not the black cat”. Most of the words in the input sentence have a direct translation in the output sentence, but are in slightly different orders, e.g. “chat noir” and “black cat”. Because of the “ne/pas” construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.\n",
        "\n",
        "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uMvAasdlzI6w"
      },
      "source": [
        "#### The Encoder\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
        "\n",
        "![encoder](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_YTIJriszI6w"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni5tVIuNzI6w"
      },
      "source": [
        "#### The Decoder\n",
        "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
        "\n",
        "**Simple Decoder**\n",
        "\n",
        "In the simplest seq2seq decoder, we only use the last output of the encoder. This last output is sometimes called the context vector as it encodes context for the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
        "![decoder](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zVdYy0A8zI6x"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        # output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_anYBECZzI6y"
      },
      "source": [
        "#### Preparing Training data\n",
        "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WR_e0NCpzI6y"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TiQI6_KUzI6z"
      },
      "source": [
        "#### Training the Model\n",
        "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the `<SOS>` token as its first input, and the last hidden state of the encoder as its first hidden state.\n",
        "\n",
        "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster [but when the trained network is exploited, it may exhibit instability](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.\n",
        "\n",
        "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement. Turn `teacher_forcing_ratio` up to use more of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uzyLpmtWzI6z"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder_hidden\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = decoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True \n",
        "    # if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xW8pT7evzI60"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7gXZYsOczI60"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Helper Fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "    \n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WQyK8PaJzI60"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "- Start a timer\n",
        "- Initialize optimizers and criterion\n",
        "- Create set of training pairs\n",
        "- Start empty losses array for plotting\n",
        "\n",
        "Then we call `train` many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4NQNyNEozI60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 500/35000 [02:13<1:34:01,  6.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2m 17s (- 158m 37s) (500 1%) 7.2398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1000/35000 [04:28<2:51:25,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4m 32s (- 154m 16s) (1000 2%) 6.1587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 1500/35000 [06:37<2:01:40,  4.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6m 41s (- 149m 29s) (1500 4%) 5.6458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 2000/35000 [08:49<3:29:05,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8m 54s (- 146m 53s) (2000 5%) 5.4334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 2500/35000 [11:05<2:46:35,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11m 9s (- 145m 3s) (2500 7%) 5.1940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 3000/35000 [13:14<1:45:16,  5.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13m 18s (- 141m 56s) (3000 8%) 5.0791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 3500/35000 [15:24<2:16:27,  3.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15m 29s (- 139m 21s) (3500 10%) 5.0107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 4000/35000 [17:39<2:31:31,  3.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17m 43s (- 137m 20s) (4000 11%) 4.9220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 4500/35000 [19:53<2:25:11,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19m 57s (- 135m 18s) (4500 12%) 4.8118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 5000/35000 [22:06<1:59:51,  4.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22m 10s (- 133m 3s) (5000 14%) 4.7537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 5500/35000 [24:17<2:19:01,  3.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24m 21s (- 130m 40s) (5500 15%) 4.6145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 6000/35000 [26:26<2:27:44,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26m 30s (- 128m 7s) (6000 17%) 4.5934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 6500/35000 [28:35<1:46:22,  4.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28m 40s (- 125m 42s) (6500 18%) 4.6037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 7000/35000 [30:47<1:52:40,  4.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30m 52s (- 123m 28s) (7000 20%) 4.4998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 7500/35000 [32:52<1:45:58,  4.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32m 56s (- 120m 46s) (7500 21%) 4.4894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 8000/35000 [35:10<2:03:48,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35m 14s (- 118m 55s) (8000 22%) 4.4774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 8500/35000 [37:22<1:19:23,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37m 26s (- 116m 45s) (8500 24%) 4.4524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 9000/35000 [39:35<2:08:38,  3.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39m 40s (- 114m 35s) (9000 25%) 4.4737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 9500/35000 [41:49<1:33:09,  4.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41m 53s (- 112m 27s) (9500 27%) 4.4188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 10000/35000 [43:59<1:51:52,  3.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44m 3s (- 110m 8s) (10000 28%) 4.3999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 10500/35000 [46:15<1:41:23,  4.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "46m 19s (- 108m 4s) (10500 30%) 4.2460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 11000/35000 [48:27<1:53:47,  3.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48m 31s (- 105m 52s) (11000 31%) 4.3119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 11500/35000 [50:37<1:26:34,  4.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50m 42s (- 103m 36s) (11500 32%) 4.3184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 12000/35000 [52:50<1:37:35,  3.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52m 55s (- 101m 25s) (12000 34%) 4.3145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 12500/35000 [55:08<1:31:10,  4.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55m 12s (- 99m 22s) (12500 35%) 4.2587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 13001/35000 [57:15<1:42:32,  3.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57m 19s (- 97m 0s) (13000 37%) 4.2724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 13499/35000 [59:34<1:51:39,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59m 38s (- 94m 59s) (13500 38%) 4.2522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 14001/35000 [1:01:49<1:30:21,  3.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61m 53s (- 92m 49s) (14000 40%) 4.2176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 14500/35000 [1:04:03<1:28:57,  3.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64m 8s (- 90m 40s) (14500 41%) 4.1948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 15000/35000 [1:06:15<1:20:15,  4.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66m 20s (- 88m 26s) (15000 42%) 4.2339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 15501/35000 [1:08:30<1:20:55,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68m 34s (- 86m 16s) (15500 44%) 4.1230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 15999/35000 [1:10:45<1:30:29,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70m 50s (- 84m 7s) (16000 45%) 4.1785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 16500/35000 [1:12:56<1:28:24,  3.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73m 0s (- 81m 51s) (16500 47%) 4.0868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 17000/35000 [1:15:09<1:51:25,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75m 14s (- 79m 39s) (17000 48%) 4.0970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 17500/35000 [1:17:21<1:05:38,  4.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77m 25s (- 77m 25s) (17500 50%) 4.1044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 18000/35000 [1:19:33<1:27:56,  3.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79m 37s (- 75m 11s) (18000 51%) 4.1177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 18500/35000 [1:21:47<1:17:32,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "81m 51s (- 73m 0s) (18500 52%) 4.1626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 18999/35000 [1:23:59<54:31,  4.89it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "84m 3s (- 70m 47s) (19000 54%) 4.1178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 19500/35000 [1:26:14<1:06:09,  3.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86m 18s (- 68m 36s) (19500 55%) 4.1481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 20000/35000 [1:28:22<1:38:11,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88m 26s (- 66m 20s) (20000 57%) 4.0742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▊    | 20500/35000 [1:30:39<49:59,  4.83it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90m 44s (- 64m 10s) (20500 58%) 4.0935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 21001/35000 [1:32:52<46:32,  5.01it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92m 56s (- 61m 57s) (21000 60%) 4.0578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 21500/35000 [1:35:01<50:11,  4.48it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95m 6s (- 59m 42s) (21500 61%) 4.0505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 22000/35000 [1:37:12<49:45,  4.35it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97m 16s (- 57m 28s) (22000 62%) 3.9570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 22500/35000 [1:39:21<54:45,  3.80it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99m 26s (- 55m 14s) (22500 64%) 4.0023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 23000/35000 [1:41:38<31:33,  6.34it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101m 42s (- 53m 3s) (23000 65%) 4.0247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 23501/35000 [1:43:51<46:02,  4.16it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "103m 55s (- 50m 51s) (23500 67%) 4.0202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▊   | 24000/35000 [1:46:04<53:59,  3.40it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106m 8s (- 48m 39s) (24000 68%) 3.9605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 24500/35000 [1:48:17<55:57,  3.13it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108m 21s (- 46m 26s) (24500 70%) 3.9416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 25001/35000 [1:50:28<41:14,  4.04it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110m 32s (- 44m 13s) (25000 71%) 4.0626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 25500/35000 [1:52:43<40:45,  3.88it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "112m 47s (- 42m 1s) (25500 72%) 4.0071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 26000/35000 [1:54:50<42:24,  3.54it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114m 54s (- 39m 46s) (26000 74%) 4.0250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 26500/35000 [1:57:04<31:07,  4.55it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "117m 8s (- 37m 34s) (26500 75%) 3.9779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 27000/35000 [1:59:12<43:56,  3.03it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "119m 16s (- 35m 20s) (27000 77%) 3.9080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 27500/35000 [2:01:26<31:09,  4.01it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "121m 30s (- 33m 8s) (27500 78%) 3.9462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 28000/35000 [2:03:34<21:58,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "123m 39s (- 30m 54s) (28000 80%) 3.9858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████▏ | 28500/35000 [2:05:48<34:26,  3.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125m 52s (- 28m 42s) (28500 81%) 4.0148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 29001/35000 [2:07:57<18:07,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128m 1s (- 26m 29s) (29000 82%) 4.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 29500/35000 [2:10:12<30:10,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130m 16s (- 24m 17s) (29500 84%) 3.9550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 30000/35000 [2:12:26<31:24,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "132m 30s (- 22m 5s) (30000 85%) 4.0163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 30501/35000 [2:14:43<15:42,  4.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "134m 47s (- 19m 53s) (30500 87%) 3.8329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 30999/35000 [2:16:52<24:40,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136m 57s (- 17m 40s) (31000 88%) 3.9165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 31500/35000 [2:19:05<13:03,  4.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "139m 9s (- 15m 27s) (31500 90%) 3.8603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 32001/35000 [2:21:18<11:31,  4.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "141m 22s (- 13m 15s) (32000 91%) 3.8859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 32500/35000 [2:23:32<09:10,  4.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143m 37s (- 11m 2s) (32500 92%) 3.8913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 33000/35000 [2:25:38<08:03,  4.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "145m 42s (- 8m 49s) (33000 94%) 3.8641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 33499/35000 [2:27:48<06:52,  3.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147m 52s (- 6m 37s) (33500 95%) 3.9084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 34000/35000 [2:30:02<04:08,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150m 7s (- 4m 24s) (34000 97%) 3.9038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 34500/35000 [2:32:14<01:53,  4.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "152m 18s (- 2m 12s) (34500 98%) 3.9108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35000/35000 [2:34:30<00:00,  3.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "154m 34s (- 0m 0s) (35000 100%) 3.8118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/Vanilla/encoder{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/Vanilla/decoder{}.pt\".format(n_iters))\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
        "encoder1.to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words)\n",
        "decoder1.to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 35000, print_every=500)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Fu80CIzI61"
      },
      "source": [
        "#### Plotting results\n",
        "Plotting is done with matplotlib, using the array of loss values `plot_losses` saved while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQk3Npc6zI61"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GstsNPB_zI61"
      },
      "source": [
        "#### Evaluation\n",
        "Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zHQoRmIezI62"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "                input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Vu62-yzI62"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VnGhPPUnzI62"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words= evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zRTPZpKEzI62"
      },
      "source": [
        "#### Training and Evaluating\n",
        "With all these helper functions in place (it looks like extra work, but it makes it easier to run multiple experiments) we can actually initialize a network and start training.\n",
        "\n",
        "Remember that the input sentences were heavily filtered. For this small dataset we can use relatively small networks of 256 hidden nodes and a single GRU layer. After about 40 minutes on a MacBook CPU we’ll get some reasonable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "uZkDNYsszI63",
        "outputId": "2358d9a8-629d-4dda-e912-0198286c3084"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym6qoZjLzI64",
        "outputId": "a345049c-bbd4-4758-edb3-dc553473beca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> sunshine cake md oranges pk lemon cake mix c vegetable oil eggs cool whip\n",
            "= heat oven to f grease x x pan and set aside grate peel and squeeze juice from oranges add enough water to orange juice to measure cup beat cake mix lrb dry rrb tablespoon orange peel oil eggs and juice in large bowl for seconds on low speed then on medium speed for minutes pour into pan bake minutes or until cake springs back when lightly touched cool serve with cool whip whipped cream and if desired sprinkle with remaining orange rind\n",
            "< preheat oven to f grease a large bowl combine flour and baking powder and salt in a large bowl combine flour and baking powder and mix well pour into pan and bake at f for minutes or until golden brown cool on wire rack <EOS>\n",
            "\n",
            "> cous cous lamb lb lean lamb cut in chunks sm butternut squash peeled arlic cloves peeled seeded cut in chunks piece of fresh ginger cut sm egg plant cut in chunk into the same size as the carrots peeled cut in garlic chunks ts cummin ripe tomato cut in half alt remove seeds and cut in tb tomato paste slices tb herresse sauce md zucchini washed cut in lg onion peeled and sliced chunks lb white turnips peeled and cn chick peas cut in cubes or chunks ts pepper c instant cous cous ts salt oz dried figs cut in piece stick of unsalted butter\n",
            "= lamb cover lamb with cold water and bring to a boil drain in colander and rinse with cold water put lamb in a large dutch oven and add cups of water puree garlic and ginger together in a blender to make a paste add to lamb along with the cummin salt and tomato paste bring to a boil and boil gently covered for minutes add all the vegetables except the last ingredients bring to a boil and simmer for minutes add the last ingredients and liquid bring to a boil for more minutes lrb gently rrb set aside cous cous bring cups of water to a boil in a large sauce pan add pepper and salt melted butter and cous cous stir to coat well stir in figs and add seasoned water stir well cover and let stand for minutes put in individual dishes make a well in the center of cous cous and fill with meat and vegetables\n",
            "< preheat oven to f grease a large bowl combine flour and salt in a saucepan and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring\n",
            "\n",
            "> cottage cheese jello salad pk jello ct small curd cottage cheese tb sugar lg carton of cool whip sm can of crushed pineapple\n",
            "= mix jello sugar and pineapple and cook until it comes to a boil cool add cottage cheese and fold in cool whip refrigerate\n",
            "< preheat oven to f grease a large bowl combine flour and baking powder and salt in a large bowl combine flour and baking powder and mix well pour into pan and bake at f for minutes or until golden brown cool on wire rack <EOS>\n",
            "\n",
            "> tyler texas chili lb ground round cn oz tomato paste bay leaves ts cayenne pepper lg onions cn oz chili beans cn oz tomatoes tb red pepper flakes cloves garlic oz canned jalapeno peppers md bell pepper diced tb chili powder ts ground cumin sliced\n",
            "= brown beef onions and bell pepper add garlic when browned add rest of the ingredients except beans and jalapenos simmer for hours add beans and jalapeno peppers and simmer for one hour longer\n",
            "< place all ingredients in a large bowl and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring occasionally add onion and garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook\n",
            "\n",
            "> teriyaki chicken wings chicken wings tb vegetable oil c teriyaki marinade sauce ts dry mustard c dry sherry ts ground ginger c honey ts garlic powder\n",
            "= so the ingredients specify using la choy substitute as needed\n",
            "< preheat oven to f grease a large bowl combine all ingredients except baking powder and salt in a saucepan bring to a boil stirring constantly cover and simmer for minutes stirring occasionally add remaining ingredients except salt and pepper to taste add to taste and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook\n",
            "\n",
            "> apricot conserve lb dried apricots finely chopped lb golden raisins rind and all lb sugar in a food processor lg oranges seeded c chopped walnuts cut in small pieces lightly toasted\n",
            "= put apricots in a large heavy saucepan and pour over just enough water to cover them bring to a boil lower the heat and simmer apricots until tender minutes add raisins sugar and chopped oranges simmer for hour stirring cool and stir in the walnuts beat this\n",
            "< preheat oven to f grease a large bowl combine flour and baking powder and salt in a large bowl stir in flour and cook for minutes stirring constantly add remaining ingredients except salt and pepper to taste add to taste and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir\n",
            "\n",
            "> rice stuffed mushrooms lg fresh mushrooms ts salt tb chili sauce c cooked extra long grain rice tb minced onion ts ground black pepper tb lemon juice c finely chopped nut meats tb butter or margarine c melted butter\n",
            "= remove stems wash and dry mushrooms add remaining ingredients except for melted butter press rice mixture into each mushroom cavity place mushroom caps on rack in broiler drizzle with melted butter and broil until golden brown\n",
            "< preheat oven to f grease a large bowl combine flour and salt in a saucepan and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook stirring constantly until thickened and stir in remaining ingredients except cheese and cook over medium\n",
            "\n",
            "> rich cranberry coffee cake pk cream cheese oz diveded softened ts baking powder c butter or margarine ts salt c sugar c cranberries fresh or anilla frozen dry ea eggs c pecans chopped c allpurpose flour c confectioners sugar\n",
            "= in a mixing bowl beat cream cheese butter sugar and vanilla until smooth add eggs one at a time mixing mell after each addition combine cups flour baking powder and salt gradually add to butter mixture mix remaining flour with cranberries and nuts fold into batter spoon into a greased in fluted tube pan bake at deg for to min or until cake tests done let stand min before removing from the pan cool on a wire rack before serving dust with confectioners sugar servings\n",
            "< preheat oven to f grease a large bowl combine flour and baking powder and salt in a large bowl combine flour and baking powder and mix well pour into pan and bake at f for minutes or until golden brown cool on wire rack <EOS>\n",
            "\n",
            "> fricasseed chicken chickens to lb each celery stalk roughly sliced cut up or bay leaves lb chicken pieces sprigs fresh thyme or salt ts dried thyme freshly ground black pepper tb flour tb unsalted butter or margarine c chicken stock lg onions or lowsodium chicken broth peeled and roughly diced c milk lg carrots coarsely chopped ts ground nutmeg\n",
            "= rinse the chicken pieces dry pat dry and sprinkle with salt and pepper melt the butter over low heat in a large covered casserole dish or dutch oven on top of the stove add the chicken pieces and cook on all sides without browning about minutes remove pieces to a plate as they are done when all chicken is done add the onions carrots celery bay leaves and thyme and cook about minutes sprinkle the flour over the vegetables and cook stirring for seconds add the stock milk and nutmeg increase heat to high cover and bring to a boil replace the thighs and drumsticks cover and place casserole in the oven for minutes add the reserved breasts and cook for another minutes remove the casserole from the oven remove the chicken pieces from the casserole and set them aside strain the sauce through a fine sieve and discard onions carrots celery and herbs keep the chicken pieces warm in the turnedoff oven while finishing the sauce place strained sauce in a medium saucepan over medium heat and cook until stewing liquid is thick enough to cling to a wooden spoon to serve arrange the chicken in a serving casserole or on a deep serving platter and ladle the sauce over it accompany the fricassee with noodles or rice pilaf refrigerate the meat and sauce separately for up to days freeze the meat and sauce separately in batches for up to months\n",
            "< preheat oven to f grease a large bowl combine all ingredients except baking powder and salt in a saucepan bring to a boil stirring constantly cover and simmer for minutes stirring occasionally add remaining ingredients except salt and pepper to taste add to taste and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook\n",
            "\n",
            "> broccoli mushrooms in oyster sauce ea bunch broccoli in pieces ea water or chicken stock lb mushrooms sliced t vegetable oil t garlic minced t oyster sauce\n",
            "= clean broccoli trim off flowers into bitesize pieces lightly peel broccoli stalks and sliced into diagonal medallions heat wok on high add oil and when the oil is hot add garlic and stirfry seconds add broccoli stirfry rapidly until the broccoli is covered in oil when the wok is no longer oily add a splash of water or chicken stock and continue to fry stirring constantly for minutes replenishing waterchicken stock whenever wok becomes dry toss in mushrooms stir add oyster sauce stir cover and simmer at medium heat two minutes serve\n",
            "< place all ingredients in a large bowl and stir in remaining ingredients except cheese and cook over medium heat stirring constantly until thickened and bubbly add to skillet and cook for minutes stirring occasionally add onion and garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook for minutes add garlic and cook\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRYuCDwzI64"
      },
      "source": [
        "## MODEL TWO - ATTENTION SEQ2SEQ\n",
        "\n",
        "The only modification we make to the second baseline from model 1 to model 2 is to replace the default decoder with a more computationally nuanced Attention Decoder\n",
        "\n",
        "Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called attn_applied in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfkp8yzzI65"
      },
      "source": [
        "Calculating the attention weights is done with another feed-forward layer `attn`, using the decoder’s input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
        "\n",
        "![encoder-attn](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YAo-3ZvGzI65"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs): #param encoder_outputs: necessary for computing attention from decoder to all encoder values\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0iSlmKKdzI65"
      },
      "source": [
        "#### Attention Training Method\n",
        "\n",
        "This function is particularly important since it is called back to on several occasions, both by the attention-decoder and by the later paired auto-encoder experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JXNmtVggzI65"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder_hidden\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = decoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aRgSWuwWzI66"
      },
      "outputs": [],
      "source": [
        "def evaluate_attn(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5-VObipVzI66"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly_attn(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attention= evaluate_attn(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nE-XmtzYzI66"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 25) (3782052404.py, line 25)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[22], line 25\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Loss: {}print_loss_avg))\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 25)\n"
          ]
        }
      ],
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"Loss: {}\".format(print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/Attention/attnencoder{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/Attention/attndecoder{}.pt\".format(n_iters))\n",
        "    showPlot(plot_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "4P1wpz0tzI67",
        "outputId": "c4988887-a8b0-4321-cf15-56b29ea0489f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 4999/40000 [35:59<4:11:58,  2.32it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'timeSince' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m encoder \u001b[39m=\u001b[39m EncoderRNN(input_lang\u001b[39m.\u001b[39mn_words, hidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m attn_decoder \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, output_lang\u001b[39m.\u001b[39mn_words, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m trainIters_attn(encoder, attn_decoder, \u001b[39m40000\u001b[39;49m, print_every\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m)\n",
            "Cell \u001b[1;32mIn[18], line 25\u001b[0m, in \u001b[0;36mtrainIters_attn\u001b[1;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     23\u001b[0m     print_loss_avg \u001b[39m=\u001b[39m print_loss_total \u001b[39m/\u001b[39m print_every\n\u001b[0;32m     24\u001b[0m     print_loss_total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (timeSince(start, \u001b[39miter\u001b[39m \u001b[39m/\u001b[39m n_iters),\n\u001b[0;32m     26\u001b[0m                                  \u001b[39miter\u001b[39m, \u001b[39miter\u001b[39m \u001b[39m/\u001b[39m n_iters \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m, print_loss_avg))\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39m%\u001b[39m plot_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     29\u001b[0m     plot_loss_avg \u001b[39m=\u001b[39m plot_loss_total \u001b[39m/\u001b[39m plot_every\n",
            "\u001b[1;31mNameError\u001b[0m: name 'timeSince' is not defined"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters_attn(encoder, attn_decoder, 40000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKWrtbAczI67",
        "outputId": "03b2e647-a0e2-466c-b4cc-c1b5c8b565a6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'nlp' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n nlp ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "evaluateRandomly_attn(encoder, attn_decoder)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvvuFQNzI67"
      },
      "source": [
        "#### Visualizing Attention\n",
        "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
        "\n",
        "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "touKY27dzI68",
        "outputId": "e188516d-a85f-4012-9916-8f9689766569"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'nlp' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n nlp ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "output_words, attentions = evaluate_attn(\n",
        "    encoder, attn_decoder, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Orb18OQkzI68"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes and labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4OmE509wzI68",
        "outputId": "491f62b9-c608-4ac1-a502-92ff55bd41a4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'nlp' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n nlp ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate_attn(\n",
        "        encoder, attn_decoder, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 3 - AUTOENCODERS\n",
        "\n",
        "The approach here is to 'warm up' the encoders and decoders each by training autoencoders (ie. encoder-decoders training their weights on the same data) for both the ingredient list and the steps. We train each for [EPOCH], before continuing the training by loading the state dictionaries, pairing the ingredient encoder and recipe attention decoder, and continuing to fine tune the weights. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "#First create new data represent duplicated pairs\n",
        "def re_pair(paired_data):\n",
        "    sources = []\n",
        "    targets = []\n",
        "    for i in paired_data:\n",
        "        sources.append([i[0], i[0]])\n",
        "        targets.append([i[1], i[1]])\n",
        "    return sources, targets\n",
        "\n",
        "training_pairs = extract_pairs(\"Dataset/train.tsv\")\n",
        "train_src, train_trg = re_pair(training_pairs)\n",
        "\n",
        "#We can re-use the single-epoch training logic from MODEL TWO but will need to modify the training loop slightly to accept new data and of course save the states. We also do not need to plot losses.\n",
        "\n",
        "def AE_training_loop(pairs, name, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        " \n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"Average Loss: {}\".format(print_loss_avg))\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/AE/{}_encoder_{}.pt\".format(name, n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/AE/{}_decoder_{}.pt\".format(name, n_iters))\n",
        "    torch.save(decoder_optimizer.state_dict(), \"Checkpoints/AE/{}_dec_optim_{}.pt\",format(name, n_iters)) #Also necessary to save optimiser state dict to resume training later\n",
        "    torch.save(encoder_optimizer.state_dict(), \"Checkpoints/AE/{}_enc_optim_{}.pt\",format(name, n_iters))\n",
        "\n",
        "\n",
        "#Then, train target autoencoder - this can re-use the training function\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Autoencoder Training\n",
        "\n",
        "We train both encoders and decoders on the duplicates dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ae_ing_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "ae_ing_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "AE_training_loop(train_src, \"ingredients\", ae_ing_encoder, ae_ing_decoder, 20000)\n",
        "\n",
        "ae_rec_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "ae_rec_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "AE_training_loop(train_src, \"recipes\", ae_rec_encoder, ae_rec_decoder, 20000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, staple the warmed up EncoderRNN and DecoderRNN together in new training iteration, and save them as completed Encoder/Decoder pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Instantiate models\n",
        "ingredient_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "recipe_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "#Load model state dictionaries\n",
        "ingredient_encoder.load_state_dict(torch.load(\"Checkpoints/AE/ingredients_encoder_20000.pt\"))\n",
        "recipe_decoder.load_state_dict(torch.load(\"Checkpoints/AE/recipe_decoder_20000.pt\"))\n",
        "\n",
        "#Instantiate optimisers\n",
        "encoder_optimizer = optim.SGD(ingredient_encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(recipe_decoder.parameters(), lr=0.01)\n",
        "\n",
        "#Load optimiser state dictionaries\n",
        "encoder_optimizer.load_state_dict(torch.load(\"Checkpoints/AE/ingredients_enc_optim_20000.pt\"))\n",
        "decoder_optimizer.load_state_dict(torch.load(\"Checkpoints/AE/recipe_dec_optim_20000.pt\"))\n",
        "\n",
        "def AE_fine_tune(encoder, decoder, encoder_optim, decoder_optim, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optim, decoder_optim, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/AE/encoder_fine_tune_{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/AE/decoder_fine_tune_{}.pt\".format(n_iters))\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f3DHX7xtzI69"
      },
      "source": [
        "## Quantitative Evaluation\n",
        "\n",
        "Here we define metrics for the ingredient recall, extra ingredients added, and use NLTK to calculate the BLEU and METEOR scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> butterscotch brownies c butter ts baking powder c firmly packed light brown ts salt sugar ts vanilla extract egg c chopped walnuts c sifted flour\n",
            "= preheat oven to of melt butter in saucepan over low heat remove from heat stir in sugar mix until well blended cool stir in egg sift flour baking powder and salt together in bowl add to butter mixture blend well stir in vanilla and walnuts pour batter into greased and floured square pan bake for minutes cut into squares while still warm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "< preheat oven to f grease a x baking dish combine flour sugar baking powder salt and salt in a large mixing bowl mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at\n",
            "BLEU: 1.4605451666563354e-155\n",
            "\n",
            "> rice tarragon c riceuncooked c butter onionchopped ts pepper c chicken stockhot c waterboiling ts tarragoncrushed\n",
            "= heat butter in a deep skillet add rice and onions and saute stirring frequently until rice is light brown and onions are transparent add tarragon pour hot chicken stock over rice cover tightly and simmer until rice is tender lrb about minutes rrb\n",
            "< in a large pot of boiling salted water cook the onion and garlic in the oil until the onions are tender add the onion and garlic and saute until the onion is translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion\n",
            "BLEU: 0\n",
            "\n",
            "> thai shrimp broccoli pasta oz uncooked chinese noodles or c broccoli florets vermicelli broken red jalapeno pepper seeded lb medium shrimp cleaned and finely chopped tb finely chopped fresh tb fish or soy sauce gingerroot or ts cornstarch ts ginger tb finely chopped fresh cl garlic minced cilantro c chicken broth\n",
            "= cook noodles as directed on package drain and keep warm meanwhile spray wok or large skillet with nonstick cooking spray heat over high heat until hot add shrimp cook and stir minute remove shrimp from wok set side if necessary drain wok add ginger and garlic to wok cook seconds add cup of the broth broccoli and chile pepper cover and cook minutes combine remaining broth fish sauce and cornstarch mix well return shrimp to wok add broth mixture bring to a boil cook minutes or until slightlyl thickened and shrimp turns pink stir in cilantro serve with noodles\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "< in a large skillet saute the onion and garlic in the oil until the onions are translucent add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are\n",
            "BLEU: 5.4163389104701204e-232\n",
            "\n",
            "> varza acra calita braised sauerkraut lb bacon cut in small pieces c onion minced cn no can sauerkraut c water\n",
            "= fry the bacon add onion and brown slightly squeeze excess water from sauerkraut and add to bacon onion add water and let simmer until all water has evaporated serve hot\n",
            "< in a large pot of water cook the onion and garlic in the oil until the onions are tender add the onion and garlic and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook\n",
            "BLEU: 5.994164343186785e-232\n",
            "\n",
            "> tabasco classic venison chops marchand de muscadine venison chops ounces each c sliced green onions ts tabasco pepper sauce c dry white wine salt c muscadine jelly lb butter or margarine soften ts salt tb vegetable oil chopped fresh parsley\n",
            "= avery island and the country around it abound in game especially wild ducks and geese snipe woodcock doves and deer season the chops with teaspoon of the tabasco sauce and sprinkle them with salt in a large skillet melt tablespoon of the butter and the oil over mediumhigh heat in two batches cook the chops for minutes turning once and remove to a warm platter melt tablespoons of the butter in the same skillet add the green onions and cook stirring frequently for minutes or until tender stir in the wine bring to a boil and boil rapidly to reduce to cup stir in the jelly until it is melted add the remaining teaspoon tabasco sauce and salt to taste remove from the heat stir in the remaining tablespoons butter a tablespoon at a time until the sauce is slightly thickened serve over the chops sprinkle with parsley\n",
            "< in a large skillet heat the oil in a large skillet over mediumhigh heat add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the\n",
            "BLEU: 5.4163389104701204e-232\n",
            "\n",
            "> easy fruit fly trap no ingredients found\n",
            "= glass jar piece of paper and a piece of tape a little detergent put cider vinegar in the bottom of the jar lrb inch or cm or so rrb add a couple of drops of detergent to the vingar place the paper funnel on the jar set on the kitchen counter near the fruit flies are attracted to the cider vinegar which they interpret as decaying fruit easy and cheap and no zaps\n",
            "< butter a small amount of water and place in a large pot add the chicken and cook until the mixture is tender remove from the heat and stir in the remaining ingredients except the remaining ingredients except the remaining ingredients in a large bowl mix well add the remaining ingredients mix well add the remaining ingredients mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> coconut jumbles c butter or marg softened ts salt c sugar ts vanilla extract egg beaten egg white slightly beaten c flour allpurpose coconut shredded ts baking powder\n",
            "= cream butter add sugar gradually continuing to cream add eggs blend well combine flour baking powder and salt add to creamed mixture beating well stir in vanilla roll out dough about thick on a lightly floured board cut with doughnut cutter brush tops with egg white sprinkle with coconut bake at degrees for minutes or until a delicate brown southern living magazine may\n",
            "< preheat oven to f grease x baking dish combine flour sugar baking powder salt and salt in a large mixing bowl mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a\n",
            "BLEU: 1.4605451666563354e-155\n",
            "\n",
            "> spicy nachos butter busters ea pk smart temptations chips ea pk taco seasoning mix c grated nonfat cheddar cheese ea bn lettuce chopped lb skinless white turkey meat lg tomatoes chopped ground\n",
            "= cook turkey in a waxed papaer covered bowl in the microwave minutes remove and stir cook a couple of more minutes if needed drain meat and set aside prepare taco mix as directed substituting turkey for ground beef spoon taco mixture over chips sprinkle cheese on top heat in microwave for minutes sprinkle with lettuce and tomatoes top with hot sauce of desired cook one package country pride seasoned chicken strips lrb teriyaki mesquite or mexcali flavor rrb in microwave as directed on package use instead of ground turkey or chicken butter busters by pam mycoskie isbn entered by carolyn shaw\n",
            "< preheat oven to degrees f mix the flour salt pepper and salt in a large bowl mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> baked clams cherrystone clams egg slightly beaten tb butter or margarine c seasoned bread crumbs c finely chopped onion ts dried oregano leaves clove garlic peeled c seasoned dry bread crumbs and crushed tb butter or margarine melted\n",
            "= remove clams from half shell and chop coarsely set clams and shells aside in a mediumsized heatresistant nonmetallic mixing bowl place tablespoons butter heat in microwave oven seconds or until melted add onion and garlic heat uncovered in microwave oven energy minutes or until onion is tender add egg the cup bread crumbs chopped clams and oregano to onion mixture spoon mixture into reserved shells place shells on a heat resistant nonmetallic serving platter in a small bowl combine the cup seasoned bread crumbs and the tablespoons melted butter sprinkle buttered bread crumbs on top of clam mixture heat uncovered in microwave oven minutes or until heated through\n",
            "< preheat oven to degrees f grease a x baking dish mix together the flour salt and pepper in a large bowl mix the flour with the baking powder salt and pepper add the remaining ingredients mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> sauteed okra tomatoes corn lb okra stems and tips tb unsalted butter removed tb safflower oil lb tomatoes skinned and seeded c onions coarsely chopped ears fresh corn tb salt or to taste or freshly ground pepper c frozen corn kernels\n",
            "= cut okra into rounds discarding tops put tomatoes in stainless or enameled pan and cook slowly for half an hour drain any liquid cut corn from cob with sharp knife or defrost frozen corn heat butter and oil in a skillet add okra and onions cook until onions are wilted and okra has begun to brown at edges minutes turn often add reduced tomatoes and salt and cook minutes add corn and cook minutes season to taste\n",
            "< heat the oil in a large skillet over mediumhigh heat add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until\n",
            "BLEU: 6.441148769597431e-232\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words)\n",
        "encoder.load_state_dict(torch.load(\"Checkpoints/Vanilla/encoder35000\"))\n",
        "decoder.load_state_dict(torch.load(\"Checkpoints/Vanilla/decoder35000\"))\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "testing_pairs = extract_pairs(\"Dataset/test.tsv\")\n",
        "\n",
        "def evaluateModel1(encoder, decoder, data, n):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(data)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words= evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        overlap = calculate_metrics(pair[0], prediction=output_sentence)\n",
        "        print('<', output_sentence)\n",
        "        print(\"BLEU: {}\".format(overlap))\n",
        "        print('')\n",
        "\n",
        "def calculate_metrics(ground_truth, prediction):\n",
        "    ref_tokens = ground_truth.split()\n",
        "    ref_tokens = [ref_tokens]\n",
        "    candidate_tokens = prediction.split()\n",
        "    #TODO: implement METEOR, %Rec, %Spare\n",
        "    bleu = sentence_bleu(ref_tokens, candidate_tokens)\n",
        "    # meteor = \n",
        "    # ingredient_recall = \n",
        "    # extra_ingredients = \n",
        "    return bleu\n",
        "\n",
        "evaluateModel1(encoder, decoder, testing_pairs, n=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
