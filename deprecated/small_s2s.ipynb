{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "# from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from tqdm import trange\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import Vocab, vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import csv\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_recipe_processing(line):\n",
    "    title = re.findall(r'Title: (.*)', line)\n",
    "    ingredients = re.findall(r'ingredients: (.*)', line)\n",
    "    steps = re.findall(r'ingredients: .*\\n([\\s\\S]*)', line)\n",
    "    try:\n",
    "        title = title[0]\n",
    "        title = re.sub(r'[^a-zA-Z0-9_ ]', '', title)\n",
    "        ingredients = ingredients[0].replace('''\\t''', \" \")\n",
    "        ingredients = re.sub(r'[^a-zA-Z0-9_ ]', '', ingredients)\n",
    "        steps = steps[0].replace('''\\n''', \" \")\n",
    "        steps = re.sub(r'[^a-zA-Z0-9_ ]', '', steps)\n",
    "    except:\n",
    "        return None\n",
    "    return (str(title + \" \" + ingredients), str(steps))\n",
    "\n",
    "def process_rawtext(path):\n",
    "    print(\"Processing text data from {}\".format(path))\n",
    "    recipes = []\n",
    "    files = glob.glob(path + \"/*.txt\")\n",
    "    for file in files:\n",
    "        lines = open(file, encoding='utf-8').read().strip().split(\"END RECIPE\")\n",
    "        for l in lines:\n",
    "            recipe = text_to_recipe_processing(l)\n",
    "            if recipe is not None:\n",
    "                recipes.append(recipe)\n",
    "    return recipes\n",
    "\n",
    "def write_to_tsv(destination, recipe_list):\n",
    "    with open(destination, 'w',  newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter='\\t')\n",
    "        for recipe in recipe_list:\n",
    "            writer.writerow(recipe)\n",
    "\n",
    "def build_language(data_path):\n",
    "    all_ingredients = []\n",
    "    all_recipes = []\n",
    "    for path in data_path: #manual path list:\n",
    "        recipes = process_rawtext(path)\n",
    "        for r in recipes:\n",
    "            all_ingredients.append(r[0])\n",
    "            all_recipes.append(r[1])\n",
    "    ingredient_lang = Language(\"ingredients\")\n",
    "    recipe_lang = Language(\"recipes\")\n",
    "    for ing in all_ingredients:\n",
    "        ingredient_lang.addSentence(ing)\n",
    "    for rec in all_recipes:\n",
    "        recipe_lang.addSentence(rec)\n",
    "    return ingredient_lang, recipe_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text data from Cooking_Dataset/train\n",
      "Processing text data from Cooking_Dataset/test\n",
      "Processing text data from Cooking_Dataset/dev\n"
     ]
    }
   ],
   "source": [
    "train_recipes = process_rawtext(\"Cooking_Dataset/train\")\n",
    "write_to_tsv(\"Dataset/train.tsv\", train_recipes)\n",
    "test_recipes = process_rawtext(\"Cooking_Dataset/test\")\n",
    "write_to_tsv(\"Dataset/test.tsv\", test_recipes)\n",
    "dev_recipes = process_rawtext(\"Cooking_Dataset/dev\")\n",
    "write_to_tsv(\"Dataset/dev.tsv\", dev_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = get_tokenizer(tokenizer=None)\n",
    "# ct = Counter()\n",
    "# for recipe in train_recipes:\n",
    "#     ct.update(tk(recipe[0]))\n",
    "# src_vocab = vocab(ct, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
    "\n",
    "# count = Counter()\n",
    "# for recipe in train_recipes:\n",
    "#     count.update(tk(recipe[1]))\n",
    "# trg_vocab = vocab(ct, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text data from Cooking_Dataset/test\n",
      "Processing text data from Cooking_Dataset/dev\n",
      "Processing text data from Cooking_Dataset/train\n"
     ]
    }
   ],
   "source": [
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<BOS>\", 2: \"<EOS>\"}\n",
    "        self.n_words = 3  # Count PAD, SOS, and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_words\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def stoi(self, word):\n",
    "        return self.word2index[word]\n",
    "    \n",
    "    def itos(self, ndx):\n",
    "        return self.index2word[ndx]\n",
    "\n",
    "def build_language(data_path):\n",
    "    all_ingredients = []\n",
    "    all_recipes = []\n",
    "    for path in data_path: #manual path list:\n",
    "        recipes = process_rawtext(path)\n",
    "        for r in recipes:\n",
    "            all_ingredients.append(r[0])\n",
    "            all_recipes.append(r[1])\n",
    "    ingredient_lang = Language(\"ingredients\")\n",
    "    recipe_lang = Language(\"recipes\")\n",
    "    for ing in all_ingredients:\n",
    "        ingredient_lang.addSentence(ing)\n",
    "    for rec in all_recipes:\n",
    "        recipe_lang.addSentence(rec)\n",
    "    return ingredient_lang, recipe_lang\n",
    "\n",
    "\n",
    "dataset_path = [\"Cooking_Dataset/test\", \"Cooking_Dataset/dev\", \"Cooking_Dataset/train\"]\n",
    "ingredient_vocabulary, recipe_vocabulary = build_language(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5159\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ingredient_vocabulary.stoi(\"hungry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('brendas nectarineorange bavarian cream 2    envelopes unflavored gelatin 2 c  heavy cream divided 1 12 23 c  sugar divided 13  13 12 34 c  orange juice fresh if sweet 12 ts vanilla 2    egg yolks 12 c  blue berries optional but 4 lg nectarines divided highly recommended', 'brenda s nectarineorange bavarian cream  in heavy saucepan  mix gelatin and 13 cup sugar  stir in orange juice and egg yolks and blend well  let stand one minute  stir over low heat until gelatin is completely dissolved and mixture thickens slightly about 57 minutes  remove from heat  slice 2 nectarines and puree in blender or processor with the remaining 13 cup sugar  stir puree into gelatin mixture  chill  stirring occasionally  only until mixture mounds slightly when dropped from a spoon  whip 112 cups cream until stiff  fold in fruitgelatin mixture  pour into 5 cup ring or other mold  chill until firm  unmold on pretty platter for finishing  slice remaining 2 nectarines and whip remaining 12 cup cream until stiff  fold in vanilla  put in pastry bag and pipe out large rosettes  interspersing with nectarine slices crosswise on top of mold lrb or spoon dollops of cream without bag rrb  mound remaining nectarine slices in center and garnish with blueberries  serve 6 to 8 and listen to complements  well worth the work  bill birner \\n')\n"
     ]
    }
   ],
   "source": [
    "# source_f = Field(tokenize = 'spacy', init_token = '<SOS>', eos_token = '<EOS>', lower=True)\n",
    "# target_f = Field(tokenize = 'spacy', init_token = '<SOS>', eos_token = '<EOS>', lower=True)\n",
    "# train_data = TabularDataset(path=\"Dataset/train.tsv\", format=\"tsv\", fields=[('source', source_f),('target', target_f)])\n",
    "# source_f.build_vocab(train_data, min_freq = 2)\n",
    "# target_f.build_vocab(train_data, min_freq = 2)\n",
    "\n",
    "# iterator = Iterator(train_data, batch_size = BS, device=DEVICE, shuffle=True)\n",
    "\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.all_recipes = []\n",
    "        file = open(path, 'r')\n",
    "        lines = file.readlines()\n",
    "        for l in lines:\n",
    "            items = l.split(\"\"\"\\t\"\"\")\n",
    "            self.all_recipes.append(items)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_recipes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ing = self.all_recipes[index][0]\n",
    "        step = self.all_recipes[index][1]\n",
    "        return ing, step\n",
    "\n",
    "src_transform = lambda x: [ingredient_vocabulary.stoi('<BOS>')] + [ingredient_vocabulary.stoi(token) for token in tk(x)] + [ingredient_vocabulary.stoi('<EOS>')]\n",
    "trg_transform = lambda x: [recipe_vocabulary.stoi('<BOS>')] + [recipe_vocabulary.stoi(token) for token in tk(x)] + [recipe_vocabulary.stoi('<EOS>')]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    source_list, target_list = [], [] \n",
    "    for source, target in batch: \n",
    "        src_process = torch.tensor(src_transform(source)) \n",
    "        source_list.append(src_process) \n",
    "        trg_process = torch.tensor(trg_transform(target))\n",
    "        target_list.append(trg_process)\n",
    "    return pad_sequence(source_list, padding_value=3.0), pad_sequence(target_list, padding_value=3.0)\n",
    "\n",
    "recipe_data = RecipeDataset(\"Dataset/train.tsv\")\n",
    "print(recipe_data[1])\n",
    "trainloader = DataLoader(recipe_data, BS, shuffle=True, collate_fn=collate_fn)\n",
    "devloader = DataLoader(recipe_data, BS, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        # src : [sen_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        # embedded : [sen_len, batch_size, emb_dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [sen_len, batch_size, hid_dim * n_directions]\n",
    "        # hidden = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        # cell = [n_layers * n_direction, batch_size, hid_dim]\n",
    "        return hidden, cell\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=self.n_layers, dropout=dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        # input = [batch_size]\n",
    "        # hidden = [n_layers * n_dir, batch_size, hid_dim]\n",
    "        # cell = [n_layers * n_dir, batch_size, hid_dim]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input : [1, ,batch_size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch_size, emb_dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq_len, batch_size, hid_dim * n_dir]\n",
    "        # hidden = [n_layers * n_dir, batch_size, hid_dim]\n",
    "        # cell = [n_layers * n_dir, batch_size, hid_dim]\n",
    "        \n",
    "        # seq_len and n_dir will always be 1 in the decoder\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch_size, output_dim]\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            'hidden dimensions of encoder and decoder must be equal.'\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'n_layers of encoder and decoder must be equal.'\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src = [sen_len, batch_size]\n",
    "        # trg = [sen_len, batch_size]\n",
    "        # teacher_forcing_ratio : the probability to use the teacher forcing.\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # first input to the decoder is the <sos> token.\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_len):\n",
    "            # insert input token embedding, previous hidden and previous cell states \n",
    "            # receive output tensor (predictions) and new hidden and cell states.\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            # replace predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # decide if we are going to use teacher forcing or not.\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # get the highest predicted token from our predictions.\n",
    "            top1 = output.argmax(1)\n",
    "            # update input : use ground_truth when teacher_force \n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First initialize our model.\n",
    "INPUT_DIM = len(ingredient_vocabulary)\n",
    "OUTPUT_DIM = len(recipe_vocabulary)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # trg = [sen_len, batch_size]\n",
    "        # output = [trg_len, batch_size, output_dim]\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        # transfrom our output : slice off the first column, and flatten the output into 2 dim.\n",
    "        output = output[1:].view(-1, output_dim) \n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg_len-1) * batch_size]\n",
    "        # output = [(trg_len-1) * batch_size, output_dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            output = model(src, trg, 0) # turn off teacher forcing.\n",
    "            \n",
    "            # trg = [sen_len, batch_size]\n",
    "            # output = [sen_len, batch_size, output_dim]\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'<BOS>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m example, ex2 \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(ex2)\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[104], line 32\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m source_list, target_list \u001b[39m=\u001b[39m [], [] \n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m source, target \u001b[39min\u001b[39;00m batch: \n\u001b[1;32m---> 32\u001b[0m     src_process \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(src_transform(source)) \n\u001b[0;32m     33\u001b[0m     source_list\u001b[39m.\u001b[39mappend(src_process) \n\u001b[0;32m     34\u001b[0m     trg_process \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(trg_transform(target))\n",
      "Cell \u001b[1;32mIn[104], line 26\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_recipes[index][\u001b[39m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m         \u001b[39mreturn\u001b[39;00m ing, step\n\u001b[1;32m---> 26\u001b[0m src_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [ingredient_vocabulary\u001b[39m.\u001b[39;49mstoi(\u001b[39m'\u001b[39;49m\u001b[39m<BOS>\u001b[39;49m\u001b[39m'\u001b[39;49m)] \u001b[39m+\u001b[39m [ingredient_vocabulary\u001b[39m.\u001b[39mstoi(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [ingredient_vocabulary\u001b[39m.\u001b[39mstoi(\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     27\u001b[0m trg_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [recipe_vocabulary\u001b[39m.\u001b[39mstoi(\u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m)] \u001b[39m+\u001b[39m [recipe_vocabulary\u001b[39m.\u001b[39mstoi(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [recipe_vocabulary\u001b[39m.\u001b[39mstoi(\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_fn\u001b[39m(batch):\n",
      "Cell \u001b[1;32mIn[102], line 26\u001b[0m, in \u001b[0;36mLanguage.stoi\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstoi\u001b[39m(\u001b[39mself\u001b[39m, word):\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword2index[word]\n",
      "\u001b[1;31mKeyError\u001b[0m: '<BOS>'"
     ]
    }
   ],
   "source": [
    "for example, ex2 in trainloader:\n",
    "    print(ex2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Token watery not found and default index is not set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m best_valid_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m trange(N_EPOCHS):\n\u001b[1;32m---> 10\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, trainloader, optimizer, criterion, CLIP)\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProgress <3 \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(model, devloader, criterion)\n",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iterator):\n\u001b[0;32m      8\u001b[0m     src \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39msrc\n\u001b[0;32m      9\u001b[0m     trg \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mtrg\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[22], line 31\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     29\u001b[0m     src_process \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(src_transform(source)) \n\u001b[0;32m     30\u001b[0m     source_list\u001b[39m.\u001b[39mappend(src_process) \n\u001b[1;32m---> 31\u001b[0m     trg_process \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(trg_transform(target))\n\u001b[0;32m     32\u001b[0m     target_list\u001b[39m.\u001b[39mappend(trg_process)\n\u001b[0;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m pad_sequence(source_list, padding_value\u001b[39m=\u001b[39m\u001b[39m3.0\u001b[39m), pad_sequence(target_list, padding_value\u001b[39m=\u001b[39m\u001b[39m3.0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m trg_vocab \u001b[39m=\u001b[39m vocab(ct, specials\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m<unk>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<PAD>\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m src_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [src_vocab[\u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m+\u001b[39m [src_vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [src_vocab[\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> 13\u001b[0m trg_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [trg_vocab[\u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m+\u001b[39m [trg_vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [trg_vocab[\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m trg_vocab \u001b[39m=\u001b[39m vocab(ct, specials\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m<unk>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<PAD>\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m src_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [src_vocab[\u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m+\u001b[39m [src_vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [src_vocab[\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m---> 13\u001b[0m trg_transform \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [trg_vocab[\u001b[39m'\u001b[39m\u001b[39m<BOS>\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m+\u001b[39m [trg_vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tk(x)] \u001b[39m+\u001b[39m [trg_vocab[\u001b[39m'\u001b[39m\u001b[39m<EOS>\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32me:\\miniconda\\envs\\fednlp\\lib\\site-packages\\torchtext\\vocab\\vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab[token]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Token watery not found and default index is not set"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(N_EPOCHS):\n",
    "    \n",
    "    \n",
    "    train_loss = train(model, trainloader, optimizer, criterion, CLIP)\n",
    "    print(\"Progress <3 \")\n",
    "    valid_loss = evaluate(model, devloader, criterion)\n",
    "    \n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:.3f} | Valid PPL: {math.exp(valid_loss):7.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fednlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
