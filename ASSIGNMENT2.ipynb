{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dokj3AV9zI6Z"
      },
      "source": [
        "## Tutorial - Seq2Seq model for Neural Machine Translation\n",
        "This tutorial is adapted from [_NLP From Scratch: Translation with a Sequence to Sequence Network and Attention_](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) tutorial from Pytoch documentations.\n",
        "\n",
        "In this tutorial you will learn how to one language to another using neural network. Here, we treanslate English to French as example.\n",
        "\n",
        "```\n",
        "[KEY: > input, = target, < output]\n",
        "\n",
        "> il est en train de peindre un tableau .\n",
        "= he is painting a picture .\n",
        "< he is painting a picture .\n",
        "\n",
        "> pourquoi ne pas essayer ce vin delicieux ?\n",
        "= why not try that delicious wine ?\n",
        "< why not try that delicious wine ?\n",
        "\n",
        "> vous etes trop maigre .\n",
        "= you re too skinny .\n",
        "< you re all alone .\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWU237IjzI6e",
        "outputId": "c778e636-b51a-419e-dcb9-1d58072a617f"
      },
      "outputs": [],
      "source": [
        "#Generic imports and OS settings\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import matplotlib\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fZldjD8hzI6h"
      },
      "outputs": [],
      "source": [
        "## Requirements\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "from tqdm import trange\n",
        "import torch\n",
        "import nltk \n",
        "import numpy as np\n",
        "\n",
        "#Custom imports and device settings\n",
        "from numpy import transpose\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate import meteor\n",
        "from nltk.corpus import stopwords\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "teacher_forcing_ratio = 1\n",
        "ITERCOUNT = 60000\n",
        "MAX_LENGTH = 150 \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSqk3xOzI6i"
      },
      "source": [
        "### Part1 - Seq2Seq model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RxgAt3tYzI6k"
      },
      "source": [
        "Transforming one sequence to another is possible by the simple but powerful idea of the [sequence to sequence network](https://arxiv.org/abs/1409.3215), in which two recurrent neural networks work. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k8pfH3G-zI6l"
      },
      "source": [
        "#### Loading data files"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P1qodl52zI6l"
      },
      "source": [
        "The data used in this tutorial contains thousands of English to French translation pairs.\n",
        "\n",
        "This question on Open Data Stack Exchange pointed me to the open translation site https://tatoeba.org/ which has downloads available at https://tatoeba.org/eng/downloads - and better yet, someone did the extra work of splitting language pairs into individual text files here: https://www.manythings.org/anki/\n",
        "\n",
        "The English to French pairs can be found at data/eng-fra.txt. It is a tab separated list of translation pairs.\n",
        "```\n",
        "I am cold.    J'ai froid.\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "usIv7r7NzI6n"
      },
      "source": [
        "We will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). There are many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language.\n",
        "\n",
        "![vocab](https://pytorch.org/tutorials/_images/word-encoding.png)\n",
        "\n",
        "We’ll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called Lang which has word → index (word2index) and index → word (index2word) dictionaries, as well as a count of each word word2count which will be used to replace rare words later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GIF75UoszI6o"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def stoi(self, word):\n",
        "        return self.word2index[word]\n",
        "    \n",
        "    def itos(self, ndx):\n",
        "        return self.index2word[ndx]\n",
        "    \n",
        "    def contains(self, word):\n",
        "        if word in self.word2index:\n",
        "            return True\n",
        "        return False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhpa39gqzI6q"
      },
      "source": [
        "All files are in Unicode, to simplify, we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bCghv1VyzI6q"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RECIPE DATA PROCESSING\n",
        "\n",
        "Pipeline is: \n",
        "1. process raw text extracts recipe pairs from the raw text folders by calling text-to-recipe\n",
        "2. recipes are cleaned up with data normalisation and preprocessing\n",
        "3. write-tsv writes the tsv objects with the recipe list\n",
        "\n",
        "these TSV files are our new data\n",
        "\n",
        "4. extract pairs pulls the data from the tsv files\n",
        "5. the pairs are passed into build-language as well as into their own object\n",
        "6. pairs and both languages are returned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marks\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "measurements = {\"c\", \"tsp\", \"tbsp\", \"qt\", \"cn\", \"lb\", \"ts\", \"ea\", \"lg\", \"tb\"}\n",
        "stop_words.update(measurements)\n",
        "\n",
        "\n",
        "def trim_stopwords(text):\n",
        "    output = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "    output = output.lower()\n",
        "    return output\n",
        "\n",
        "def recipe_cleanup(all_recipes):\n",
        "    outputs = []\n",
        "    for recipe in all_recipes:\n",
        "        clean_ing = trim_stopwords(recipe[0])\n",
        "        clean_step = trim_stopwords(recipe[1])\n",
        "        outputs.append((clean_ing, clean_step))\n",
        "    return outputs\n",
        "\n",
        "    #     - lower (10 mins)\n",
        "    # - dissolve contractions (30 mins)\n",
        "    # - remove stopwords (20 mins)\n",
        "\n",
        "# test_recipe = trim_stopwords(\"Ours is the Question of Glory\")\n",
        "# print(test_recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_recipe_processing(line):\n",
        "    title = re.findall(r'Title: (.*)', line)\n",
        "    ingredients = re.findall(r'ingredients: (.*)', line)\n",
        "    steps = re.findall(r'ingredients: .*\\n([\\s\\S]*)', line)\n",
        "    try:\n",
        "        title = title[0]\n",
        "        title = re.sub(r'[^a-zA-Z ]', '', title) #remove non-alpha or underscore characters\n",
        "        title = re.sub(r'\\s+', ' ', title) #remove excess spaces\n",
        "        ingredients = ingredients[0].replace('''\\t''', \" \") #replace tab with space for better formatting\n",
        "        ingredients = re.sub(r'[^a-zA-Z ]', '', ingredients)\n",
        "        ingredients = re.sub(r'\\s+', ' ', ingredients)\n",
        "        steps = steps[0].replace('''\\n''', \" \") #replace newline in steps with space\n",
        "        steps = re.sub(r'[^a-zA-Z ]', '', steps)\n",
        "        steps = re.sub(r'\\s+', ' ', steps)\n",
        "    except:\n",
        "        return None\n",
        "    return (str(title + \" \" + ingredients), str(steps))\n",
        "\n",
        "def process_rawtext(path):\n",
        "    print(\"Processing text data from {}\".format(path))\n",
        "    recipes = []\n",
        "    files = glob.glob(path + \"/*.txt\")\n",
        "    for file in files:\n",
        "        lines = open(file, encoding='utf-8').read().strip().split(\"END RECIPE\")\n",
        "        for l in lines:\n",
        "            recipe = text_to_recipe_processing(l)\n",
        "            if recipe is not None:\n",
        "                recipes.append(recipe)\n",
        "    return recipes\n",
        "\n",
        "def write_to_tsv(destination, recipe_list):\n",
        "    with open(destination, 'w',  newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile, delimiter='\\t')\n",
        "        for recipe in recipe_list:\n",
        "            writer.writerow(recipe)\n",
        "\n",
        "def build_language(data_paths):\n",
        "    all_ingredients = []\n",
        "    all_recipes = []\n",
        "    for path in data_paths: #manual path list:\n",
        "        recipes = extract_pairs(path)\n",
        "        for r in recipes:\n",
        "            all_ingredients.append(r[0])\n",
        "            all_recipes.append(r[1])\n",
        "    ingredient_lang = Lang(\"ingredients\")\n",
        "    recipe_lang = Lang(\"recipes\")\n",
        "    for ing in all_ingredients:\n",
        "        ingredient_lang.addSentence(ing)\n",
        "    for rec in all_recipes:\n",
        "        recipe_lang.addSentence(rec)\n",
        "    return ingredient_lang, recipe_lang\n",
        "\n",
        "# def extract_pairs(path):\n",
        "#     all_recipes = []\n",
        "#     file = open(path, 'r')\n",
        "#     lines = file.readlines()\n",
        "#     for l in lines:\n",
        "#         items = [normalizeString(s) for s in l.split(\"\"\"\\t\"\"\")]\n",
        "#         all_recipes.append(items)\n",
        "#     all_recipes = filterPairs(all_recipes)\n",
        "#     return all_recipes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing text data from Cooking_Dataset/train\n",
            "Processing text data from Cooking_Dataset/dev\n",
            "Processing text data from Cooking_Dataset/test\n"
          ]
        }
      ],
      "source": [
        "### Recipes with stopwords included\n",
        "# train_recipes = process_rawtext(\"Cooking_Dataset/train\")\n",
        "# write_to_tsv(\"Dataset/train.tsv\", train_recipes)\n",
        "# test_recipes = process_rawtext(\"Cooking_Dataset/test\")\n",
        "# write_to_tsv(\"Dataset/test.tsv\", test_recipes)\n",
        "# dev_recipes = process_rawtext(\"Cooking_Dataset/dev\")\n",
        "# write_to_tsv(\"Dataset/dev.tsv\", dev_recipes)\n",
        "\n",
        "# ###Recipes without stopwords\n",
        "# train_recipes = process_rawtext(\"Cooking_Dataset/train\")\n",
        "# cleaned_train = recipe_cleanup(train_recipes)\n",
        "# write_to_tsv(\"Clean_Data/train.tsv\", cleaned_train)\n",
        "# dev_recipes = process_rawtext(\"Cooking_Dataset/dev\")\n",
        "# cleaned_dev = recipe_cleanup(dev_recipes)\n",
        "# write_to_tsv(\"Clean_Data/dev.tsv\", cleaned_dev)\n",
        "# test_recipes = process_rawtext(\"Cooking_Dataset/test\")\n",
        "# cleaned_test = recipe_cleanup(test_recipes)\n",
        "# write_to_tsv(\"Clean_Data/test.tsv\", cleaned_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKaq7QGzI6r"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split lines into pairs. The used files contain English → Other Language, so I added the `reverse` flag to reverse the pairs, in case that you want to translate from Other Language → English ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fG4twu-pzI6s"
      },
      "outputs": [],
      "source": [
        "# def readLangs(lang1, lang2, reverse=False):\n",
        "#     print(\"Reading lines...\")\n",
        "\n",
        "#     # Read the file and split into lines\n",
        "#     file_name = 'data/%s-%s.txt' % (lang1, lang2)\n",
        "#     lines = open(file_name, encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "\n",
        "#     # Split every line into pairs and normalize\n",
        "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "#     # Reverse pairs, make Lang instances\n",
        "#     if reverse:\n",
        "#         pairs = [list(reversed(p)) for p in pairs]\n",
        "#         input_lang = Lang(lang2)\n",
        "#         output_lang = Lang(lang1)\n",
        "#     else:\n",
        "#         input_lang = Lang(lang1)\n",
        "#         output_lang = Lang(lang2)\n",
        "\n",
        "#     return input_lang, output_lang, pairs\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TyAuHpoGzI6s"
      },
      "source": [
        "Pairs can be later extracted from the .tsv files and returned as recipes, after being filtered for passing max length and the strings normalised (just in case any stray data makes it through the cleanup phase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JFBL2updzI6t"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def extract_pairs(path):\n",
        "    all_recipes = []\n",
        "    file = open(path, 'r')\n",
        "    lines = file.readlines()\n",
        "    for l in lines:\n",
        "        items = [normalizeString(s) for s in l.split(\"\"\"\\t\"\"\")]\n",
        "        all_recipes.append(items)\n",
        "    all_recipes = filterPairs(all_recipes)\n",
        "    return all_recipes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DZgHx1ICzI6u"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "- Read text file and split into lines, split lines into pairs\n",
        "- Normalize text, filter by length and content\n",
        "- Make word lists from sentences in pairs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvic3S4UzI6u",
        "outputId": "4c2fb10f-a4ea-4c6a-b471-b7525b0e821a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MAX_LENGTH' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# def prepareData(lang1, lang2, reverse=False):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#     print(\"Read %s sentence pairs\" % len(pairs))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m# input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print(random.choice(pairs))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m dataset_path \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mClean_Data/train.tsv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mClean_Data/dev.tsv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mClean_Data/test.tsv\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m input_lang, output_lang \u001b[39m=\u001b[39m build_language(dataset_path)\n\u001b[0;32m     20\u001b[0m pairs \u001b[39m=\u001b[39m extract_pairs(\u001b[39m\"\u001b[39m\u001b[39mClean_Data/train.tsv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m dev_pairs \u001b[39m=\u001b[39m extract_pairs(\u001b[39m\"\u001b[39m\u001b[39mClean_Data/dev.tsv\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[19], line 41\u001b[0m, in \u001b[0;36mbuild_language\u001b[1;34m(data_paths)\u001b[0m\n\u001b[0;32m     39\u001b[0m all_recipes \u001b[39m=\u001b[39m []\n\u001b[0;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m data_paths: \u001b[39m#manual path list:\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     recipes \u001b[39m=\u001b[39m extract_pairs(path)\n\u001b[0;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m recipes:\n\u001b[0;32m     43\u001b[0m         all_ingredients\u001b[39m.\u001b[39mappend(r[\u001b[39m0\u001b[39m])\n",
            "Cell \u001b[1;32mIn[20], line 24\u001b[0m, in \u001b[0;36mextract_pairs\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     22\u001b[0m     items \u001b[39m=\u001b[39m [normalizeString(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m l\u001b[39m.\u001b[39msplit(\u001b[39m\"\"\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\"\"\u001b[39m)]\n\u001b[0;32m     23\u001b[0m     all_recipes\u001b[39m.\u001b[39mappend(items)\n\u001b[1;32m---> 24\u001b[0m all_recipes \u001b[39m=\u001b[39m filterPairs(all_recipes)\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m all_recipes\n",
            "Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36mfilterPairs\u001b[1;34m(pairs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfilterPairs\u001b[39m(pairs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m [pair \u001b[39mfor\u001b[39;49;00m pair \u001b[39min\u001b[39;49;00m pairs \u001b[39mif\u001b[39;49;00m filterPair(pair)]\n",
            "Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfilterPairs\u001b[39m(pairs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m [pair \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m pairs \u001b[39mif\u001b[39;00m filterPair(pair)]\n",
            "Cell \u001b[1;32mIn[20], line 11\u001b[0m, in \u001b[0;36mfilterPair\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfilterPair\u001b[39m(p):\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(p[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m<\u001b[39m MAX_LENGTH \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m     12\u001b[0m         \u001b[39mlen\u001b[39m(p[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m<\u001b[39m MAX_LENGTH\n",
            "\u001b[1;31mNameError\u001b[0m: name 'MAX_LENGTH' is not defined"
          ]
        }
      ],
      "source": [
        "# def prepareData(lang1, lang2, reverse=False):\n",
        "#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "#     print(\"Read %s sentence pairs\" % len(pairs))\n",
        "#     pairs = filterPairs(pairs)\n",
        "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "#     print(\"Counting words...\")\n",
        "#     for pair in pairs:\n",
        "#         input_lang.addSentence(pair[0])\n",
        "#         output_lang.addSentence(pair[1])\n",
        "#     print(\"Counted words:\")\n",
        "#     print(input_lang.name, input_lang.n_words)\n",
        "#     print(output_lang.name, output_lang.n_words)\n",
        "#     return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "# input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "# print(random.choice(pairs))\n",
        "dataset_path = [\"Clean_Data/train.tsv\", \"Clean_Data/dev.tsv\", \"Clean_Data/test.tsv\"]\n",
        "input_lang, output_lang = build_language(dataset_path)\n",
        "pairs = extract_pairs(\"Clean_Data/train.tsv\")\n",
        "dev_pairs = extract_pairs(\"Clean_Data/dev.tsv\")\n",
        "test_pairs = extract_pairs(\"Clean_Data/test.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['marinated chicken mike peters chicken cut up cut each ts garlic powder large piece into two parts ts white pepper c oil ts marjoram c vinegar ts rosemary ts onion powder ts salt', 'salt each piece of chicken combine oil vinegar onion powder garlic powder pepper marjoram rosemary and salt place chicken in marinade and refrigerate over night turn chicken once or twice as it marinates broil chicken on grill or in broiler once or twice during the cooking process dip chicken into the marinade']\n"
          ]
        }
      ],
      "source": [
        "print(pairs[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pair_summary_stats(pairs, name):\n",
        "    ingredients = [pairs[i][0] for i in range(len(pairs))]\n",
        "    recipes = [pairs[i][1] for i in range(len(pairs))]\n",
        "    ingredient_stats = [len(r) for r in ingredients]\n",
        "    recipe_stats = [len(r) for r in recipes]\n",
        "    ing_stats = summary_statistics(ingredient_stats)\n",
        "    rec_stats = summary_statistics(recipe_stats)\n",
        "    print(\"Maximum length of ingredients from {} set: {}\".format(name, ing_stats[0]))\n",
        "    print(\"Minimum length of ingredients from {} set: {}\".format(name, ing_stats[1]))\n",
        "    print(\"Mean length of ingredients from {} set: {}\".format(name, ing_stats[2]))\n",
        "    print(\"Maximum length of recipes from {} set: {}\".format(name, rec_stats[0]))\n",
        "    print(\"Minimum length of recipes from {} set: {}\".format(name, rec_stats[1]))\n",
        "    print(\"Mean length of recipes from {} set: {}\".format(name, rec_stats[2]))\n",
        "\n",
        "def summary_statistics(input_list):\n",
        "    l_max = max(input_list)\n",
        "    l_min = max(input_list)\n",
        "    l_mean = sum(input_list)/len(input_list)\n",
        "    return (l_max, l_min, l_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of ingredients corpus: 29726\n",
            "Length of recipes corpus: 29236\n",
            "######\n",
            "Maximum length of ingredients from train set: 1805\n",
            "Minimum length of ingredients from train set: 1805\n",
            "Mean length of ingredients from train set: 203.50929768209045\n",
            "Maximum length of recipes from train set: 3867\n",
            "Minimum length of recipes from train set: 3867\n",
            "Mean length of recipes from train set: 482.7535549960934\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of ingredients corpus: {}\".format(input_lang.n_words))\n",
        "print(\"Length of recipes corpus: {}\".format(output_lang.n_words))\n",
        "print(\"######\")\n",
        "pair_summary_stats(pairs, \"train\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "imdZM1z3zI6v"
      },
      "source": [
        "### MODEL DEFINITION - MODEL ONE\n",
        "A Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps.\n",
        "\n",
        "A Sequence to Sequence network, or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence.\n",
        "\n",
        "![seq2seq](https://pytorch.org/tutorials/_images/seq2seq.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFHCitqzI6v"
      },
      "source": [
        "Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages.\n",
        "\n",
        "Consider the sentence “Je ne suis pas le chat noir” → “I am not the black cat”. Most of the words in the input sentence have a direct translation in the output sentence, but are in slightly different orders, e.g. “chat noir” and “black cat”. Because of the “ne/pas” construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words.\n",
        "\n",
        "With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uMvAasdlzI6w"
      },
      "source": [
        "#### The Encoder\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
        "\n",
        "![encoder](https://pytorch.org/tutorials/_images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_YTIJriszI6w"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni5tVIuNzI6w"
      },
      "source": [
        "#### The Decoder\n",
        "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
        "\n",
        "**Simple Decoder**\n",
        "\n",
        "In the simplest seq2seq decoder, we only use the last output of the encoder. This last output is sometimes called the context vector as it encodes context for the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
        "![decoder](https://pytorch.org/tutorials/_images/decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zVdYy0A8zI6x"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        # output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_anYBECZzI6y"
      },
      "source": [
        "#### Preparing Training data\n",
        "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR_e0NCpzI6y"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TiQI6_KUzI6z"
      },
      "source": [
        "#### Training the Model\n",
        "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the `<SOS>` token as its first input, and the last hidden state of the encoder as its first hidden state.\n",
        "\n",
        "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster [but when the trained network is exploited, it may exhibit instability](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can “pick up” the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.\n",
        "\n",
        "Because of the freedom PyTorch’s autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement. Turn `teacher_forcing_ratio` up to use more of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uzyLpmtWzI6z"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder_hidden\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = decoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True \n",
        "    # if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xW8pT7evzI60"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7gXZYsOczI60"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Helper Fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "    \n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WQyK8PaJzI60"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "- Start a timer\n",
        "- Initialize optimizers and criterion\n",
        "- Create set of training pairs\n",
        "- Start empty losses array for plotting\n",
        "\n",
        "Then we call `train` many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nQk3Npc6zI61"
      },
      "outputs": [],
      "source": [
        "def validate(encoder, decoder, target_tensor, input_tensor, criterion, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "        loss = 0\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "                input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            try:\n",
        "                loss += criterion(decoder_output, target_tensor[di])\n",
        "            except:\n",
        "                loss += loss.item()/len(decoded_words)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return loss/len(decoded_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4NQNyNEozI60"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, input_lang, output_lang, val_data, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    val_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs), input_lang, output_lang)\n",
        "                      for i in range(n_iters)]\n",
        "    validation_pairs = [tensorsFromPair(random.choice(val_data), input_lang, output_lang)\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            val = validate(encoder, decoder, target_tensor, input_tensor, criterion, MAX_LENGTH)\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/Vanilla/encoder{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/Vanilla/decoder{}.pt\".format(n_iters))\n",
        "    plotloss = np.asarray(plot_losses)\n",
        "    np.save(\"Logs/vanilla{}loss.npy\".format(n_iters), plotloss)\n",
        "    plotval = np.asarray(val_losses)\n",
        "    np.save(\"Logs/vanilla{}val.npy\".format(n_iters), plotval)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1000/60000 [02:57<3:08:00,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3m 11s (- 188m 39s) (1000 1%) 7.1113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 2000/60000 [05:49<1:53:34,  8.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6m 4s (- 176m 13s) (2000 3%) 6.2421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 2999/60000 [08:44<3:44:38,  4.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8m 59s (- 170m 41s) (3000 5%) 5.9338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 3999/60000 [11:33<1:54:39,  8.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11m 48s (- 165m 21s) (4000 6%) 5.6802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4999/60000 [14:28<3:09:30,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14m 42s (- 161m 49s) (5000 8%) 5.5680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 6000/60000 [17:19<3:11:59,  4.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17m 33s (- 158m 1s) (6000 10%) 5.4717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 7001/60000 [20:06<2:11:19,  6.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20m 20s (- 154m 2s) (7000 11%) 5.3060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 8000/60000 [22:59<3:40:30,  3.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23m 14s (- 151m 4s) (8000 13%) 5.2457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 8999/60000 [25:49<3:31:30,  4.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26m 4s (- 147m 42s) (9000 15%) 5.2437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 10001/60000 [28:43<1:33:34,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28m 57s (- 144m 48s) (10000 16%) 5.1408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 11000/60000 [31:33<2:25:24,  5.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31m 47s (- 141m 39s) (11000 18%) 5.1474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 11998/60000 [34:17<2:17:54,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34m 32s (- 138m 10s) (12000 20%) 5.1079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 13000/60000 [37:03<2:43:27,  4.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37m 18s (- 134m 51s) (13000 21%) 5.0514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 14000/60000 [39:42<2:26:58,  5.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39m 56s (- 131m 15s) (14000 23%) 4.9807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 15000/60000 [42:29<1:58:58,  6.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42m 43s (- 128m 11s) (15000 25%) 4.9369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 16000/60000 [45:14<2:02:55,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45m 29s (- 125m 5s) (16000 26%) 4.9243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 17000/60000 [48:01<1:47:45,  6.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48m 16s (- 122m 5s) (17000 28%) 4.9880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 18000/60000 [50:43<1:55:56,  6.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50m 58s (- 118m 55s) (18000 30%) 4.8410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 18999/60000 [53:27<1:55:10,  5.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53m 42s (- 115m 53s) (19000 31%) 4.8911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 20000/60000 [56:15<1:24:14,  7.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56m 30s (- 113m 0s) (20000 33%) 4.8523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 21000/60000 [58:59<1:28:50,  7.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59m 14s (- 110m 0s) (21000 35%) 4.8347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 22000/60000 [1:01:43<2:31:29,  4.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61m 57s (- 107m 1s) (22000 36%) 4.7909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 23002/60000 [1:04:24<1:23:49,  7.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64m 39s (- 104m 0s) (23000 38%) 4.7575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 24000/60000 [1:07:07<1:37:28,  6.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67m 21s (- 101m 2s) (24000 40%) 4.7863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 25000/60000 [1:09:48<2:14:03,  4.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70m 2s (- 98m 4s) (25000 41%) 4.7423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 26000/60000 [1:12:31<2:13:44,  4.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72m 45s (- 95m 9s) (26000 43%) 4.7826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 27001/60000 [1:15:11<1:40:53,  5.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75m 26s (- 92m 12s) (27000 45%) 4.6486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 28000/60000 [1:17:57<2:01:48,  4.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78m 11s (- 89m 22s) (28000 46%) 4.7038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 29000/60000 [1:20:38<1:49:37,  4.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80m 53s (- 86m 28s) (29000 48%) 4.5733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 30000/60000 [1:23:26<1:49:46,  4.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83m 41s (- 83m 41s) (30000 50%) 4.6896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 31000/60000 [1:26:13<1:41:25,  4.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86m 28s (- 80m 53s) (31000 51%) 4.6497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 32001/60000 [1:28:55<1:05:28,  7.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89m 10s (- 78m 1s) (32000 53%) 4.5844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 33001/60000 [1:31:40<1:04:38,  6.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91m 55s (- 75m 12s) (33000 55%) 4.6772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 34000/60000 [1:34:23<1:14:06,  5.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "94m 37s (- 72m 21s) (34000 56%) 4.6765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 35001/60000 [1:37:08<57:29,  7.25it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97m 23s (- 69m 33s) (35000 58%) 4.6625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 36000/60000 [1:39:52<1:10:11,  5.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100m 6s (- 66m 44s) (36000 60%) 4.6068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 37000/60000 [1:42:42<53:13,  7.20it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102m 56s (- 63m 59s) (37000 61%) 4.5761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 38001/60000 [1:45:25<1:01:22,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105m 40s (- 61m 10s) (38000 63%) 4.5844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 39000/60000 [1:48:08<57:53,  6.05it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108m 22s (- 58m 21s) (39000 65%) 4.5809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 40000/60000 [1:50:58<50:38,  6.58it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111m 13s (- 55m 36s) (40000 66%) 4.5315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 41001/60000 [1:53:44<39:42,  7.97it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "113m 58s (- 52m 49s) (41000 68%) 4.5606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 41999/60000 [1:56:30<50:01,  6.00it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "116m 44s (- 50m 2s) (42000 70%) 4.5499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 43000/60000 [1:59:10<35:16,  8.03it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "119m 25s (- 47m 12s) (43000 71%) 4.6280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 44001/60000 [2:01:54<38:11,  6.98it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "122m 8s (- 44m 24s) (44000 73%) 4.5754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 45000/60000 [2:04:42<32:41,  7.65it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124m 57s (- 41m 39s) (45000 75%) 4.5101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 46000/60000 [2:07:24<40:28,  5.77it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127m 39s (- 38m 51s) (46000 76%) 4.4837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 47000/60000 [2:10:11<42:14,  5.13it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "130m 26s (- 36m 4s) (47000 78%) 4.4957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 48000/60000 [2:12:57<37:55,  5.27it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "133m 12s (- 33m 18s) (48000 80%) 4.4488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 49000/60000 [2:15:42<29:59,  6.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "135m 57s (- 30m 31s) (49000 81%) 4.3552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 49999/60000 [2:18:29<28:22,  5.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138m 44s (- 27m 44s) (50000 83%) 4.4490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 51000/60000 [2:21:12<25:19,  5.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "141m 27s (- 24m 57s) (51000 85%) 4.4810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 52000/60000 [2:23:59<31:48,  4.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "144m 14s (- 22m 11s) (52000 86%) 4.4051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 53000/60000 [2:26:47<22:19,  5.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147m 1s (- 19m 25s) (53000 88%) 4.4473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 54000/60000 [2:29:31<22:00,  4.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149m 46s (- 16m 38s) (54000 90%) 4.4105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 55000/60000 [2:32:14<15:02,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "152m 28s (- 13m 51s) (55000 91%) 4.5049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 56000/60000 [2:34:58<12:29,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155m 13s (- 11m 5s) (56000 93%) 4.3908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 57000/60000 [2:37:46<05:47,  8.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158m 0s (- 8m 18s) (57000 95%) 4.3742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 58000/60000 [2:40:29<08:27,  3.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160m 43s (- 5m 32s) (58000 96%) 4.4047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 59000/60000 [2:43:07<02:10,  7.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163m 22s (- 2m 46s) (59000 98%) 4.3501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60000/60000 [2:45:54<00:00,  6.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "166m 9s (- 0m 0s) (60000 100%) 4.4357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
        "encoder1.to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words)\n",
        "decoder1.to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 60000, input_lang=input_lang, output_lang=output_lang, val_data = dev_pairs, print_every=1000, plot_every=100)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Fu80CIzI61"
      },
      "source": [
        "#### Plotting results\n",
        "Plotting is done with matplotlib, using the array of loss values `plot_losses` saved while training."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GstsNPB_zI61"
      },
      "source": [
        "#### Evaluation\n",
        "Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zHQoRmIezI62"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "                input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Vu62-yzI62"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VnGhPPUnzI62"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words= evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zRTPZpKEzI62"
      },
      "source": [
        "#### Training and Evaluating\n",
        "With all these helper functions in place (it looks like extra work, but it makes it easier to run multiple experiments) we can actually initialize a network and start training.\n",
        "\n",
        "Remember that the input sentences were heavily filtered. For this small dataset we can use relatively small networks of 256 hidden nodes and a single GRU layer. After about 40 minutes on a MacBook CPU we’ll get some reasonable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "uZkDNYsszI63",
        "outputId": "2358d9a8-629d-4dda-e912-0198286c3084"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym6qoZjLzI64",
        "outputId": "a345049c-bbd4-4758-edb3-dc553473beca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> tomatoleek soup ripe red tomatoes fresh parsley large leek garlic cloves minced olive oil oz tomato paste dry red wine dill hungarian paprika marjoram thyme salt pepper taste\n",
            "= cut tomatoes quarters parsley process well pureed dice rest tomatoes set aside slice white part leek slices chop tender green leaves discard tougher part leaves wash carefully put leeks large pot along reserved green leaves garlic olive oil cover cups stock bring boil lower heat simmer minutes add pureed diced tomatoes add rest ingredients simmer low heat minutes chill serve nava atlas vegetariana\n",
            "< heat oil heavy large skillet add onion garlic saute tender add tomatoes cook stirring frequently minutes add tomatoes tomato paste cook stirring occasionally add tomatoes tomato paste cook stirring occasionally add tomatoes cook another minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add salt pepper taste simmer uncovered minutes add salt pepper taste simmer uncovered minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer uncovered minutes add tomatoes cook another minutes add salt pepper taste simmer\n",
            "\n",
            "> chinese chicken salad chicken breasts powdered drumstickthighs sesame oil vegetable oil toasted almonds finely squares wanton dough cut chopped inch strips thinly sliced green pk rice noodles onions white part liquid mustard salt chinese fivespice head lettuce shredded\n",
            "= place chicken pot cover w water bring boil simmer min remove drain paper towels place vegetable oil deepfryer heat test readiness dropping rice noodle oil sinks oil nt hot enough pops immediately put dough strips fry light tan color remove drain paper towels divide noodles parts deepfry separately drain paper towels deepfry chicken min remove drain paper towels bone cut strips including skin place chicken meat large bowl add mustard fivespice powder sesame oil soy sauce almonds green onions salt mix well add crispfried wonton strips noodles mix well pile salad bed lettuce nt toss\n",
            "< combine flour salt pepper add chicken broth stir well add chicken broth bring boil reduce heat simmer uncovered hour stirring occasionally add water heat uncovered microwave oven minutes stir cooked rice stir fry minutes add chicken broth stir heat uncovered microwave oven minutes stir rice mixture heat uncovered microwave oven minutes stir rice mixture heat uncovered microwave oven minutes stir rice mixture heat uncovered microwave oven minutes stir rice mixture heat uncovered microwave oven minutes stir rice mixture heat uncovered microwave oven minutes <EOS>\n",
            "\n",
            "> sourdough strawberry cake salt fruit topping flour pt strawberries hulled butter sugar baking powder whipped topping sourdough starter heavy cream nutmeg amaretto heavy cream sugar sugar\n",
            "= mix flour baking powder nutmeg sugar salt cut butter till resembles corse meal beat starter cup heavy cream egg together till well blended pour dry ingredients mix together fork holds together loose ball pat lightly greased floured round square pan set aside rest preheating oven f oven temp bake shortcake minutes lightly browned cool pan turn still warm slice half horizontally wash hull strwberries crush enough make cup mix sugar spread bottom layer shortcake top half heavy cream whipped sugar amaretto slice remaining berries put whipped cream top remaining shortcake berries remaining whipped cream sourdough starter\n",
            "< preheat oven f spray flour x x baking pan melt butter margarine large skillet add flour stir smooth add milk stir well stir milk vanilla pour prepared pan bake minutes cake tests done cool pan minutes remove pan cool completely serving <EOS>\n",
            "\n",
            "> nb potato soup potatoes peeled salt milk celery salt slices onion pepper butter pn pinch cayanne pepper flour chopped parsley\n",
            "= cook potatoes boiling salted water soft drain push strainer blend fine scald milk onion remove onion add milk potatoes slowly large pot melt butter add next five ingredients stir potato mixture simmer minutes add parsley\n",
            "< combine potatoes onion parsley salt pepper large bowl add milk potatoes onion parsley salt pepper mix well add potatoes potato mixture mix well add potatoes potato mixture mix well add potatoes potato mixture mix well pour greased inch square pan bake degrees minutes <EOS>\n",
            "\n",
            "> basic basalmic vinaigrette basalmic vinegar garlic cloves sliced olive oil thinly\n",
            "= whisk ingredients together let stand minutes using remove garlic using\n",
            "< place ingredients blender blend smooth add salt taste <EOS>\n",
            "\n",
            "> okra extravaganza pineapple fresh green pepper bell red julienned fronds included okra chopped bn scallions chopped soy sauce garlic cloves crushed sherry dry inger freshly grated vinegar rice wine\n",
            "= slice pineapple half lengthwise remove fruit pineapple set shells aside remove discard core cut pineapple chunks set aside combine scallions garlic ginger pepper okra soy sauce sherry wok stirfry high heat vegetables tendercrisp minutes add pineapple chunks cover continue cooking minutes spoon pineapple shells serve immediately\n",
            "< combine ingredients except parsley bowl mix well add dressing toss well cover chill hours serving <EOS>\n",
            "\n",
            "> potatoes parmesan butter margarine grated parmesan cheese melted garlic powder fresh idaho potato sliced salt inch thick paprika buttery flavored crackers pepper crushed\n",
            "= medium bowl toss butter potatoes coat small bowl combine remaining ingredients coat potatoes mixture inch microwavesafe pie plate arrange coated potatoes single layer sprinkle remaining crumb mixture cook high minutes potatoes tender turning dish\n",
            "< preheat oven f butter flour baking sheet melt butter skillet add flour cook stirring constantly minutes add flour cook stirring constantly minutes add salt pepper cook stirring constantly minutes add salt pepper cook stirring constantly minutes add salt pepper cook stirring constantly minutes remove heat stir parsley serve hot <EOS>\n",
            "\n",
            "> cabbage kobenhaven casserole beef ground md onion garlic clove minced salt oz tomato sauce cinnamon ground cloves thyme basil cabbage shredded\n",
            "= brown ground beef large skillet onions garlic drain fat add remaining ingredients except cabbage meat mixture simmer minutes put half cabbage quart casserole dish top half meat mixture top remaining cabbage finally top cabbage remaining meat mixture cover casserole bake preheated oven degrees f minutes magazine years ago sent mom easy minutes preparation minutes cooking measure spices lrb transcribed suzanne barnettscott rrb\n",
            "< combine ingredients except parsley bowl add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add water necessary add salt taste simmer uncovered hour stirring occasionally add water necessary add salt taste simmer uncovered hour stirring occasionally add water necessary add salt taste simmer uncovered hour stirring occasionally add water necessary add water necessary prevent sticking add water necessary add salt taste simmer uncovered hour stirring occasionally add water necessary add salt taste simmer uncovered hour stirring occasionally add\n",
            "\n",
            "> gobi dal lentils cauliflower masoor dal pink lentils ground turmeric sm cauliflower juice lemon md onions finely chopped chicken broth ghee oil oz desiccated coconut ground chili flour freshly ground black pepper salt ground cumin oz raw cashew nuts ground coriander\n",
            "= wash lentils well drain heat ghee oil large saucpan fry onions soften add chili pepper cumin coriander turmeric stir well cook seconds add lentils stir well ensure grain coated add lemon juice cut cauliflower small florets add pan add chicken stock coconut bring boil simmer minutes mix flour liquid form smooth paste stir saucepan add salt cashews cook minutes lentils formed thick sauce\n",
            "< wash lentils cut pork inch cubes place bowl add salt pepper mix well add salt pork pork cover simmer hour <EOS>\n",
            "\n",
            "> ginger peach chicken x chicken breast halves salt oz peach slices lite syrup sliced water chestnutsdrain cornstarch hot cooked rice grated gingerroot oz pkg frozen pea pods cooked\n",
            "= large skillet nonstick spray preheat skillet medium heat add chicken cook medium heat minutes till tender longer pink turn brown evenly remove skillet keep warm meanwhile drain peaches reserving juice add water juice equal cup stir cornstarch gingerroot salt add skillet cook stir till thickened bubbly cook stir minute heat serving platter individual plates arrange rice pea pods chicken spoon sauce chicken\n",
            "< combine flour salt pepper stir chicken broth heat boiling stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil uncovered stirring constantly boil minutes stir cornstarch mixture heat uncovered microwave oven minutes stir chicken broth heat boiling reduce heat simmer uncovered minutes stir chicken broth parsley heat boiling reduce heat simmer uncovered minutes stir chicken broth parsley heat boiling reduce heat simmer uncovered minutes stir chicken broth parsley heat boiling reduce heat simmer uncovered minutes stir cornstarch mixture heat uncovered microwave oven minutes stir chicken broth parsley heat boiling reduce heat simmer uncovered minutes stir occasionally remove heat stir parsley serve hot cooked rice <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, decoder1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRYuCDwzI64"
      },
      "source": [
        "## MODEL TWO - ATTENTION SEQ2SEQ\n",
        "\n",
        "The only modification we make to the second baseline from model 1 to model 2 is to replace the default decoder with a more computationally nuanced Attention Decoder\n",
        "\n",
        "Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called attn_applied in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfkp8yzzI65"
      },
      "source": [
        "Calculating the attention weights is done with another feed-forward layer `attn`, using the decoder’s input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
        "\n",
        "![encoder-attn](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "YAo-3ZvGzI65"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs): #param encoder_outputs: necessary for computing attention from decoder to all encoder values\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden, cell) = self.lstm(output, (hidden, cell))\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, cell, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0iSlmKKdzI65"
      },
      "source": [
        "#### Attention Training Method\n",
        "\n",
        "This function is particularly important since it is called back to on several occasions, both by the attention-decoder and by the later paired auto-encoder experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JXNmtVggzI65"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 1\n",
        "\n",
        "\n",
        "def train_attn(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_cell = encoder_hidden\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden, encoder_cell = encoder(\n",
        "            input_tensor[ei], encoder_hidden, encoder_cell)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_cell = decoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_attention(encoder, decoder, input_tensor, target_tensor, criterion, max_length = MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "        loss = 0 \n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            try:\n",
        "                loss += criterion(decoder_output, target_tensor[di])\n",
        "            except:\n",
        "                loss += loss.item()/len(decoded_words)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return loss.item()/len(decoded_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aRgSWuwWzI66"
      },
      "outputs": [],
      "source": [
        "def test_attention(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "        loss = 0 \n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, decoder_cell, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5-VObipVzI66"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly_attn(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attention= test_attention(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> chinese sauce looo basic sauce dark soy sauce ginger root thin soy sauce five whole flowerets star sugar anise water peanut oil dried chili peppers sl cloves garlic split\n",
            "= add ingredients saucepan boil minutes refrigerate sauce simmer foods sauce foods absorb salty taste may need add soy sauce compensate basic sauce used slowsimmer number foods\n",
            "< combine ingredients except oil wok large skillet wok heat oil hot add oil hot add oil oil hot add oil wok oil hot add oil hot oil hot add garlic cook minutes side turn heat add oil wok add garlic cook seconds add onion cook seconds add water soy sauce stir well serve <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly_attn(encoder=encoder, decoder=attn_decoder,n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "nE-XmtzYzI66"
      },
      "outputs": [],
      "source": [
        "def trainIters_attn(encoder, decoder, n_iters, input_lang, output_lang, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    plot_losses = []\n",
        "    validation_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs) , input_lang, output_lang)\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"Loss: {}\".format(print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            valloss = validation_attention(encoder, decoder, input_tensor, target_tensor, criterion, MAX_LENGTH)\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            validation_losses.append(valloss)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/Attention/attnencoder{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/Attention/attndecoder{}.pt\".format(n_iters))\n",
        "    plotloss = np.asarray(plot_losses)\n",
        "    validloss = np.asarray(validation_losses)\n",
        "    np.save(\"Logs/attention{}loss.npy\".format(n_iters), plotloss)\n",
        "    np.save(\"Logs/attention{}val.npy\".format(n_iters), validloss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "4P1wpz0tzI67",
        "outputId": "c4988887-a8b0-4321-cf15-56b29ea0489f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 10.439402988978795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [00:00<00:01,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 10.445953369140625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 10.431387271521226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters_attn(encoder, attn_decoder, 3, input_lang, output_lang, print_every=1, plot_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKWrtbAczI67",
        "outputId": "03b2e647-a0e2-466c-b4cc-c1b5c8b565a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> havregrynskage oat cakes butter unsalted oatmeal instant sugar granulated corn syrup white\n",
            "= melt butter skillet stir sugar add oatmeal cook minutes stirring occasionally oatmeal golden brown remove heat stir corn syrup rinse custard cups muffin tins cold water shake excess moisture pack bottoms sides oatmeal mixture dividing equally refrigerate least hours loosen cakes running knife around edges gently slide serve cold buttermilk soup\n",
            "< mix ingredients together store airtight container <EOS>\n",
            "\n",
            "> herman cinnamon rolls herman salt baking powder flour soda oil margerine stick butter melted brown sugar nuts\n",
            "= mix herman salt baking powder flour soda oil form dough knead lightly roll inch thickness floured surface spread soft margerine sprinkle cinnamon sugar roll jelly roll cut inch slices spread topping bottom x place roll slices top flat side bake oven minutes remove immediately overturning cookie sheet combine stick melted margerine brown sugar nuts\n",
            "< preheat oven f grease muffin tins grease large baking pan combine flour sugar salt cinnamon large bowl mix butter egg whites soft dough turn dough onto lightly floured surface knead smooth elastic minutes turn dough onto floured surface knead smooth elastic minutes turn dough onto floured surface knead smooth elastic minutes turn dough onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn dough onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn dough onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto floured surface knead smooth elastic minutes turn onto lightly floured surface knead smooth elastic\n",
            "\n",
            "> huntington chicken pound hen cream shell macaroni butter velveeta cheese diced flour broth bread crumbs\n",
            "= stew chicken season taste cut cubes cook macaroni salt water drain thicken broth flour mix chicken macaroni cheese broth put x inch pan brown bread crumbs butter add cream mix spread top chicken mixture bake degrees minutes\n",
            "< preheat oven degrees f butter flour salt pepper large bowl combine eggs milk egg white mix well add butter mixture mix well pour mixture greased quart casserole cover microwave high minutes heated <EOS>\n",
            "\n",
            "> tourta athineiki orangewalnut cakeathens style butter sweet granulated sugar eggs orangejuice grated rind allpurpose flour baking powder salt walnuts coarsely chopped confectioners sugar opt\n",
            "= cream butter light fluffy gradually add sugar continuing beat add eggs one time beating well medium speed addition gradually add orange juice rind meanwhile sift flour baking powder salt gradually add batter add walnuts last blend another minute medium high speed pour greased lightly floured inch tube pan bake moderate oven lrb f rrb minutes color light chestnut cake springs back touch lrb watch carefully cake bakes quickly rrb turn onto wire rack round side dust confectioners sugar cool thoroughly slicing\n",
            "< preheat oven f butter flour baking powder salt large bowl cream butter sugar together beat eggs one time beat eggs one time beating well addition sift flour baking powder salt add creamed mixture alternately milk mixture mix well pour batter greased floured inch square baking pan bake f minutes turn oven temperature degrees f bake minutes turn oven temperature f bake minutes turn oven temperature degrees f bake minutes turn oven temperature f bake minutes turn oven temperature f bake minutes turn oven temperature f bake minutes turn oven temperature f bake minutes turn oven temperature degrees f bake minutes turn oven temperature degrees f <EOS>\n",
            "\n",
            "> doublechocolate layer cake bon appetit oz bittersweet unsweetened semisweet chocolate chopped sticks unsalted butter eggs separated sugar firmly packed brown sugar purpose flour ground toasted hazelnuts cream tartar oz bittersweet unsweetened semisweet chocolate chopped espresso strong coffee stick unsalted butter\n",
            "= preheat oven f butter two inch diameter springform pans inchhigh sides line pans parchment butter parchment melt chocolate butter heavy large saucepan low heat stirring constantly smooth whisk yolks sugars large bowl whisk warm chocolate mixture mix flour nuts using electric mixer beat whites cream tartar another large bowl soft peaks gently fold whites batter several additions divide batter evenly prepared pans bake cakes rise crack top toothpick inserted center comes thick batter still attached minutes cool cakes completely pans racks cover let stand room temperature stir ingredients heavy large saucepan low heat chocolate butter melted mixture smooth refrigerate jus firm enough spread whisking occasionally hour release pan sides cakes turn cakes peel parchment place cake layer platter spread frosting top second cake layer spread remaining frosting top sides cake\n",
            "< preheat oven f butter flour mixing bowl combine butter sugar egg yolks vanilla beat electric mixer medium speed electric mixer medium speed minutes scraping bowl occasionally beat egg whites soft peaks form fold batter gently batter gently fold batter gently fold batter pour batter prepared pan bake minutes toothpick inserted center comes clean cool pan rack <EOS>\n",
            "\n",
            "> baked chicken tomato sauce chicken breasts halves basil chopped tomatoes thyme small onion chopped oregano tomato paste garlic cloves minced sweet red pepper chopped crushed red pepper opt\n",
            "= arrange chicken bottom ovenproof casserole coated nostick spray place tomatoes onions red peppers tomato paste basil thyme oregano garlic red pepper blender process medium speed smooth pour sauce chicken cover bake f minutes remove cover continue baking minutes\n",
            "< combine ingredients except chicken broth bring boil reduce heat simmer minutes stirring occasionally serve chicken <EOS>\n",
            "\n",
            "> mocha chip muffins skim milk cocoa powder safflower oil flour unsweetened applesauce sugar egg substitute egg baking powder instant coffee dissolved cinnamon water semisweet chocolate chips\n",
            "= spray muffin cups vegetable cooking spray preheat oven degrees combine milk oil applesauce egg substitute coffee mixture medium bowl combine remaining ingredients large bowl add wet ingredients dry mixing combined fill muffin cups full bake minutes tester inserted center comes clean\n",
            "< combine flour sugar baking powder salt large bowl mix egg whites oil egg whites beat egg whites soft peaks form fold batter gently fold batter spoon batter greased muffin cups bake f minutes golden brown <EOS>\n",
            "\n",
            "> rhubarb jelly rhubarb cut optional piece pk liquid fruit pectin oz sugar dr red food coloring\n",
            "= grind rhubarb food processor grinder strain jelly bag reserving cup juice pour juice large kettle add sugar food coloring desired bring boil high heat stirring constantly add pectin bring full rolling boil boil min stirring constantly remove heat let stand minutes skim foam pour hot hot jars leaving headspace adjust caps process min boilingwater bath half pints\n",
            "< put ingredients blender food processor process well blended store airtight container <EOS>\n",
            "\n",
            "> spaetzle cheese noodles butter margarine dry mustard onionssliced small rings spaetzle noodles oz emmenthaler cheese grated chives chopped\n",
            "= heat butter frypan add onions brown lightly toss cheese dry mustard add cooked noodles cooked onions cheese mix well place mixture ovenproof casserole bake degrees f minutes hot bubbly sprinkle top chopped chives serving\n",
            "< combine ingredients except butter saucepan bring boil simmer minutes stirring occasionally serve immediately <EOS>\n",
            "\n",
            "> cold capellini squid oz cooked squid thinly sliced shiitake mushrooms cup cup pesto sauce cup tomato vinegar crussy wholegrain rolls cup fresh lemon juice mediumsize bowl salt combine squid freshly ground pepper vinegar lemon juice apellini cooked al dente salt peppper mix cups well cup diced red onion large bowl combine cup cooked peas cooked capellini cup cup thinly sliced\n",
            "= tomato onions peas mushrooms toss mix well add tbls pesto sauce tossing mix well serve divide capellini evenly among four bowls top seasoned squid garnish sprinkle remaining tomato onion peas mushrooms paint edge bowl remaining pesto sauce serve whole grain rolls\n",
            "< combine ingredients mix well pour mixture greased quart casserole cover microwave high minutes heated <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly_attn(encoder, attn_decoder)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvvuFQNzI67"
      },
      "source": [
        "#### Visualizing Attention\n",
        "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
        "\n",
        "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "touKY27dzI68",
        "outputId": "e188516d-a85f-4012-9916-8f9689766569"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'nlp' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n nlp ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "output_words, attentions = test_attention(\n",
        "    encoder, attn_decoder, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Orb18OQkzI68"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes and labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4OmE509wzI68",
        "outputId": "491f62b9-c608-4ac1-a502-92ff55bd41a4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'nlp' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n nlp ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = test_attention(\n",
        "        encoder, attn_decoder, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL 3 - AUTOENCODERS\n",
        "\n",
        "The approach here is to 'warm up' the encoders and decoders each by training autoencoders (ie. encoder-decoders training their weights on the same data) for both the ingredient list and the steps. We train each for [EPOCH], before continuing the training by loading the state dictionaries, pairing the ingredient encoder and recipe attention decoder, and continuing to fine tune the weights. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#First create new data represent duplicated pairs\n",
        "def re_pair(paired_data):\n",
        "    sources = []\n",
        "    targets = []\n",
        "    for i in paired_data:\n",
        "        sources.append([i[0], i[0]])\n",
        "        targets.append([i[1], i[1]])\n",
        "    return sources, targets\n",
        "\n",
        "training_pairs = extract_pairs(\"Clean_Data/train.tsv\")\n",
        "train_src, train_trg = re_pair(training_pairs)\n",
        "\n",
        "#We can re-use the single-epoch training logic from MODEL TWO but will need to modify the training loop slightly to accept new data and of course save the states. We also do not need to plot losses.\n",
        "\n",
        "def AE_training_loop(pairs, name, encoder, decoder, n_iters, input_lang, output_lang, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs), input_lang, output_lang)\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        " \n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"Average Loss: {}\".format(print_loss_avg))\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/AE/{}_encoder_{}.pt\".format(name, n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/AE/{}_decoder_{}.pt\".format(name, n_iters))\n",
        "    torch.save(decoder_optimizer.state_dict(), \"Checkpoints/AE/{}_dec_optim_{}.pt\".format(name, n_iters)) #Also necessary to save optimiser state dict to resume training later\n",
        "    torch.save(encoder_optimizer.state_dict(), \"Checkpoints/AE/{}_enc_optim_{}.pt\".format(name, n_iters))\n",
        "\n",
        "\n",
        "#Then, train target autoencoder - this can re-use the training function\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Autoencoder Training\n",
        "\n",
        "We train both encoders and decoders on the duplicates dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1000/20000 [03:01<1:05:53,  4.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 7.288514762552162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 1999/20000 [06:01<46:13,  6.49it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 6.331298516426755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 3000/20000 [08:57<54:10,  5.23it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 6.0358120431411955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 4001/20000 [11:56<50:38,  5.27it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.81758999001565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 5001/20000 [14:50<35:20,  7.07it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.680114111571367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 6000/20000 [17:48<34:07,  6.84it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.569747595997876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 7001/20000 [20:50<36:25,  5.95it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.543540254899497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 8000/20000 [23:47<45:22,  4.41it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.416150746459968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 9001/20000 [26:38<25:47,  7.11it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.309886947387344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 10001/20000 [29:34<25:07,  6.63it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.220870566131888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 11001/20000 [32:40<20:47,  7.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.157565733951362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 11999/20000 [35:39<23:11,  5.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.1340026351606145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 12999/20000 [38:35<23:13,  5.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.008685103019934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 14000/20000 [41:28<13:54,  7.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 5.002209836913369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 15000/20000 [44:21<12:36,  6.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.921798479977218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 15999/20000 [47:12<09:09,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.874630419052859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 17001/20000 [50:13<10:22,  4.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.883381383576844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 18001/20000 [53:08<04:36,  7.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.813930044489898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 19001/20000 [56:04<02:23,  6.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.723309008001425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [59:02<00:00,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Loss: 4.730463602211124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "format() argument 2 must be str, not int",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m ae_ing_encoder \u001b[39m=\u001b[39m EncoderRNN(input_lang\u001b[39m.\u001b[39mn_words, hidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m ae_ing_decoder \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, input_lang\u001b[39m.\u001b[39mn_words, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m AE_training_loop(train_src, \u001b[39m\"\u001b[39;49m\u001b[39mingredients\u001b[39;49m\u001b[39m\"\u001b[39;49m, ae_ing_encoder, ae_ing_decoder, input_lang\u001b[39m=\u001b[39;49minput_lang, output_lang\u001b[39m=\u001b[39;49minput_lang, n_iters \u001b[39m=\u001b[39;49m \u001b[39m20000\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m ae_rec_encoder \u001b[39m=\u001b[39m EncoderRNN(output_lang\u001b[39m.\u001b[39mn_words, hidden_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m ae_rec_decoder \u001b[39m=\u001b[39m AttnDecoderRNN(hidden_size, output_lang\u001b[39m.\u001b[39mn_words, dropout_p\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
            "Cell \u001b[1;32mIn[25], line 41\u001b[0m, in \u001b[0;36mAE_training_loop\u001b[1;34m(pairs, name, encoder, decoder, n_iters, input_lang, output_lang, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     39\u001b[0m torch\u001b[39m.\u001b[39msave(encoder\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mCheckpoints/AE/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_encoder_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, n_iters))\n\u001b[0;32m     40\u001b[0m torch\u001b[39m.\u001b[39msave(decoder\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mCheckpoints/AE/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_decoder_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, n_iters))\n\u001b[1;32m---> 41\u001b[0m torch\u001b[39m.\u001b[39msave(decoder_optimizer\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mCheckpoints/AE/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_dec_optim_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mformat\u001b[39m(name, n_iters)) \u001b[39m#Also necessary to save optimiser state dict to resume training later\u001b[39;00m\n\u001b[0;32m     42\u001b[0m torch\u001b[39m.\u001b[39msave(encoder_optimizer\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mCheckpoints/AE/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_enc_optim_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mformat\u001b[39m(name, n_iters))\n",
            "\u001b[1;31mTypeError\u001b[0m: format() argument 2 must be str, not int"
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "\n",
        "ae_ing_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "ae_ing_decoder = AttnDecoderRNN(hidden_size, input_lang.n_words, dropout_p=0.1).to(device)\n",
        "AE_training_loop(train_src, \"ingredients\", ae_ing_encoder, ae_ing_decoder, input_lang=input_lang, output_lang=input_lang, n_iters = 20000)\n",
        "\n",
        "ae_rec_encoder = EncoderRNN(output_lang.n_words, hidden_size).to(device)\n",
        "ae_rec_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "AE_training_loop(train_trg, \"recipes\", ae_rec_encoder, ae_rec_decoder, input_lang=output_lang, output_lang=output_lang, n_iters=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, staple the warmed up EncoderRNN and DecoderRNN together in new training iteration, and save them as completed Encoder/Decoder pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Instantiate models\n",
        "ingredient_encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "recipe_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "#Load model state dictionaries\n",
        "ingredient_encoder.load_state_dict(torch.load(\"Checkpoints/AE/ingredients_encoder_20000.pt\"))\n",
        "recipe_decoder.load_state_dict(torch.load(\"Checkpoints/AE/recipe_decoder_20000.pt\"))\n",
        "\n",
        "#Instantiate optimisers\n",
        "encoder_optimizer = optim.SGD(ingredient_encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(recipe_decoder.parameters(), lr=0.01)\n",
        "\n",
        "#Load optimiser state dictionaries\n",
        "encoder_optimizer.load_state_dict(torch.load(\"Checkpoints/AE/ingredients_enc_optim_20000.pt\"))\n",
        "decoder_optimizer.load_state_dict(torch.load(\"Checkpoints/AE/recipe_dec_optim_20000.pt\"))\n",
        "\n",
        "def AE_fine_tune(encoder, decoder, encoder_optim, decoder_optim, input_lang, output_lang, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs), input_lang, output_lang)\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in trange(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train_attn(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optim, decoder_optim, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    torch.save(encoder.state_dict(), \"Checkpoints/AE/encoder_fine_tune_{}.pt\".format(n_iters))\n",
        "    torch.save(decoder.state_dict(), \"Checkpoints/AE/decoder_fine_tune_{}.pt\".format(n_iters))\n",
        "    plotloss = np.asarray(plot_losses)\n",
        "    np.save(\"Logs/autoencoder{}loss.npy\".format(n_iters), plotloss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODEL FOUR - ALCHEMY\n",
        "\n",
        "This model is so named due to the fact that it, like alchemy, is a step or two removed from cooking, but fun to experiment with all the same.\n",
        "\n",
        "Here, I build on the work of [PAPER] to create a lightweight heuristic filter for the text generation. Here, I persist the best Seq2Seq model from the previous three (based on its loss metric) as the underlying model. Then, when sampling from the model, I apply a heuristic beam search. This creates a pair of constraints to be satisfied by each line of generated text. Whenever an *ingredient* would be generated, it is checked against the list of ingredients in the ingredients input list, with a small loss reward A more nuanced version of this method might follow Kiddon et. al.'s Neural Checklist Models. Because the Attention weights on the checklists are learned, the importance of the checklist weights in generation can also be learned (here, PyTorch's autograd feature is an elegant way of implementing this). I instead use the heuristic to preferentially persist any beams whose generation meets the constraint over beams which do not. For example:\n",
        "\n",
        "Ingredients:\n",
        "- chicken, paprika, onion, garlic\n",
        "\n",
        "Current generation:\n",
        "- Add the [ ]\n",
        "\n",
        "Beams (k = 2):\n",
        "- onion (loss = 5.6)\n",
        "- carrot (loss = 5.1)\n",
        "- beans (loss = 4.6)\n",
        "- capers (loss = 7.7)\n",
        "\n",
        "Alchemy will select onion, since it meets the constraint despite having a higher loss, and beans, to persist into the next two beams (with the sentence candidates thus being \"Add the onions\" and \"Add the beans\"). This is very lightweight since the heuristic can be applied purely at time of inference, and does not add to the model's training time whatsoever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Order of operations for alchemy, which receives two dictionaries representing the results of each beam\n",
        "#for each dictionary, need to process the OUTPUT to create two new candidate dictionaries, \n",
        "def alchemy(k:int, candidates, condition, ingredient_lang:Lang, output_lang):\n",
        "    unpacked_candidates = []\n",
        "    for c in candidates:\n",
        "        vec = c[\"out\"] #Access output vector\n",
        "        topv, topi = vec.data.topk(k) #Extract top k losses and indices\n",
        "        for i in range(k):\n",
        "            decoder_input = topi[k].squeeze().detach() #New decoder input on candidate vector will\n",
        "            loss = topv[k].item()\n",
        "            word = topi[k].item()\n",
        "            new_sentence = c[\"sentence\"]\n",
        "            new_sentence.append(output_lang.index2word(word))\n",
        "            new_loss = c[\"avg_loss\"] + loss\n",
        "            new_candidate = {\"in\": decoder_input, \"hidden\":c[\"hidden\"], \"cell\":c[\"cell\"], \"sentence\":new_sentence, \"avg_loss\": new_loss}\n",
        "            unpacked_candidates.append(new_candidate)\n",
        "    unpacked_candidates = sorted(unpacked_candidates, key=lambda d:d[\"avg_loss\"])\n",
        "    meets_cond = []\n",
        "    cond_na = []\n",
        "    fails_cond = []\n",
        "    for c in unpacked_candidates:\n",
        "        key_word = c[\"sentence\"][-1]\n",
        "        if ingredient_lang.contains(key_word):\n",
        "            if key_word in condition:\n",
        "                meets_cond.append(c)\n",
        "                continue\n",
        "            fails_cond.append(c)\n",
        "            continue\n",
        "        cond_na.append(c)\n",
        "    outputs = meets_cond + cond_na + fails_cond\n",
        "    stop_clause = False\n",
        "    if \"<EOS>\" in outputs[0][\"sentence\"]:\n",
        "        if \"<EOS>\" in outputs[1][\"sentence\"]:\n",
        "            stop_clause = True\n",
        "    return [outputs[0], outputs[1]], stop_clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def alchemy_inference(encoder, decoder, sentence, input_lang, output_lang, k = 2, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        condition = sentence.split()\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_cell = encoder_hidden\n",
        "        loss = 0 \n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden, encoder_cell)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_cell = decoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "        beams = [{\"in\":decoder_input, \"hidden\":decoder_hidden, \"cell\":decoder_cell, \"sentence\":[\"<SOS>\"], \"avg_loss\":0} ]\n",
        "        #case: need to overwrite\n",
        "            # set beam[1][3] = candidate[3]\n",
        "        # beams = (decoder_input, decoder_hidden, decoder_cell), (decoder_input, decoder_hidden, decoder_cell)]\n",
        "        # sentence_history = {1:['<SOS>'], 2:['<SOS>']}\n",
        "        for di in range(max_length):\n",
        "            candidates = []\n",
        "            for beam in beams:\n",
        "                decoder_output, decoder_hidden, decoder_cell, decoder_attention = decoder(\n",
        "                    beam['in'], beam['hidden'], beam['cell'], encoder_outputs)\n",
        "                decoder_attentions[di] = decoder_attention.data\n",
        "                c = {\"out\": decoder_output, \"hidden\": decoder_hidden, \"cell\": decoder_cell, \"sentence\": beam[\"sentence\"], \"avg_loss\": beam[\"avg_loss\"]}\n",
        "                candidates.append(c)\n",
        "                #candidates list looks like:\n",
        "                #[ (out, hidden, cell, sentence), (out, hidden, cell, sentence)]\n",
        "                # sort on output\n",
        "                # get TWO candidates, which are going to be the new beams\n",
        "\n",
        "                # topv, topi = decoder_output.data.topk(1)\n",
        "                # if topi.item() == EOS_token: # Here down to next comment is just logic for generating and appending words.\n",
        "                #     decoded_words.append('<EOS>')\n",
        "                #     break\n",
        "                # else:\n",
        "                #     decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            beams, stop_clause = alchemy(k, candidates, condition, input_lang, output_lang)\n",
        "            if stop_clause:\n",
        "                break\n",
        "\n",
        "            # decoder_input = topi.squeeze().detach()  # New decoder input given topk\n",
        "\n",
        "        return beams[0][\"sentence\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'hi': 1}, {'hi': 3}, {'hi': 6}, {'hi': 10}]\n"
          ]
        }
      ],
      "source": [
        "temp = [{\"hi\":1}, {\"hi\":6}, {\"hi\":3}, {\"hi\":10}]\n",
        "temp = sorted(temp, key=lambda d:d[\"hi\"])\n",
        "print(temp)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f3DHX7xtzI69"
      },
      "source": [
        "## Quantitative Evaluation\n",
        "\n",
        "Here we define metrics for the ingredient recall, extra ingredients added, and use NLTK to calculate the BLEU and METEOR scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> butterscotch brownies c butter ts baking powder c firmly packed light brown ts salt sugar ts vanilla extract egg c chopped walnuts c sifted flour\n",
            "= preheat oven to of melt butter in saucepan over low heat remove from heat stir in sugar mix until well blended cool stir in egg sift flour baking powder and salt together in bowl add to butter mixture blend well stir in vanilla and walnuts pour batter into greased and floured square pan bake for minutes cut into squares while still warm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "< preheat oven to f grease a x baking dish combine flour sugar baking powder salt and salt in a large mixing bowl mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at\n",
            "BLEU: 1.4605451666563354e-155\n",
            "\n",
            "> rice tarragon c riceuncooked c butter onionchopped ts pepper c chicken stockhot c waterboiling ts tarragoncrushed\n",
            "= heat butter in a deep skillet add rice and onions and saute stirring frequently until rice is light brown and onions are transparent add tarragon pour hot chicken stock over rice cover tightly and simmer until rice is tender lrb about minutes rrb\n",
            "< in a large pot of boiling salted water cook the onion and garlic in the oil until the onions are tender add the onion and garlic and saute until the onion is translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion\n",
            "BLEU: 0\n",
            "\n",
            "> thai shrimp broccoli pasta oz uncooked chinese noodles or c broccoli florets vermicelli broken red jalapeno pepper seeded lb medium shrimp cleaned and finely chopped tb finely chopped fresh tb fish or soy sauce gingerroot or ts cornstarch ts ginger tb finely chopped fresh cl garlic minced cilantro c chicken broth\n",
            "= cook noodles as directed on package drain and keep warm meanwhile spray wok or large skillet with nonstick cooking spray heat over high heat until hot add shrimp cook and stir minute remove shrimp from wok set side if necessary drain wok add ginger and garlic to wok cook seconds add cup of the broth broccoli and chile pepper cover and cook minutes combine remaining broth fish sauce and cornstarch mix well return shrimp to wok add broth mixture bring to a boil cook minutes or until slightlyl thickened and shrimp turns pink stir in cilantro serve with noodles\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\miniconda\\envs\\nlp\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "< in a large skillet saute the onion and garlic in the oil until the onions are translucent add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are\n",
            "BLEU: 5.4163389104701204e-232\n",
            "\n",
            "> varza acra calita braised sauerkraut lb bacon cut in small pieces c onion minced cn no can sauerkraut c water\n",
            "= fry the bacon add onion and brown slightly squeeze excess water from sauerkraut and add to bacon onion add water and let simmer until all water has evaporated serve hot\n",
            "< in a large pot of water cook the onion and garlic in the oil until the onions are tender add the onion and garlic and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook\n",
            "BLEU: 5.994164343186785e-232\n",
            "\n",
            "> tabasco classic venison chops marchand de muscadine venison chops ounces each c sliced green onions ts tabasco pepper sauce c dry white wine salt c muscadine jelly lb butter or margarine soften ts salt tb vegetable oil chopped fresh parsley\n",
            "= avery island and the country around it abound in game especially wild ducks and geese snipe woodcock doves and deer season the chops with teaspoon of the tabasco sauce and sprinkle them with salt in a large skillet melt tablespoon of the butter and the oil over mediumhigh heat in two batches cook the chops for minutes turning once and remove to a warm platter melt tablespoons of the butter in the same skillet add the green onions and cook stirring frequently for minutes or until tender stir in the wine bring to a boil and boil rapidly to reduce to cup stir in the jelly until it is melted add the remaining teaspoon tabasco sauce and salt to taste remove from the heat stir in the remaining tablespoons butter a tablespoon at a time until the sauce is slightly thickened serve over the chops sprinkle with parsley\n",
            "< in a large skillet heat the oil in a large skillet over mediumhigh heat add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the\n",
            "BLEU: 5.4163389104701204e-232\n",
            "\n",
            "> easy fruit fly trap no ingredients found\n",
            "= glass jar piece of paper and a piece of tape a little detergent put cider vinegar in the bottom of the jar lrb inch or cm or so rrb add a couple of drops of detergent to the vingar place the paper funnel on the jar set on the kitchen counter near the fruit flies are attracted to the cider vinegar which they interpret as decaying fruit easy and cheap and no zaps\n",
            "< butter a small amount of water and place in a large pot add the chicken and cook until the mixture is tender remove from the heat and stir in the remaining ingredients except the remaining ingredients except the remaining ingredients in a large bowl mix well add the remaining ingredients mix well add the remaining ingredients mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> coconut jumbles c butter or marg softened ts salt c sugar ts vanilla extract egg beaten egg white slightly beaten c flour allpurpose coconut shredded ts baking powder\n",
            "= cream butter add sugar gradually continuing to cream add eggs blend well combine flour baking powder and salt add to creamed mixture beating well stir in vanilla roll out dough about thick on a lightly floured board cut with doughnut cutter brush tops with egg white sprinkle with coconut bake at degrees for minutes or until a delicate brown southern living magazine may\n",
            "< preheat oven to f grease x baking dish combine flour sugar baking powder salt and salt in a large mixing bowl mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a time beating well after each addition stir in vanilla add vanilla and mix well add eggs one at a\n",
            "BLEU: 1.4605451666563354e-155\n",
            "\n",
            "> spicy nachos butter busters ea pk smart temptations chips ea pk taco seasoning mix c grated nonfat cheddar cheese ea bn lettuce chopped lb skinless white turkey meat lg tomatoes chopped ground\n",
            "= cook turkey in a waxed papaer covered bowl in the microwave minutes remove and stir cook a couple of more minutes if needed drain meat and set aside prepare taco mix as directed substituting turkey for ground beef spoon taco mixture over chips sprinkle cheese on top heat in microwave for minutes sprinkle with lettuce and tomatoes top with hot sauce of desired cook one package country pride seasoned chicken strips lrb teriyaki mesquite or mexcali flavor rrb in microwave as directed on package use instead of ground turkey or chicken butter busters by pam mycoskie isbn entered by carolyn shaw\n",
            "< preheat oven to degrees f mix the flour salt pepper and salt in a large bowl mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and mix well add the milk and\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> baked clams cherrystone clams egg slightly beaten tb butter or margarine c seasoned bread crumbs c finely chopped onion ts dried oregano leaves clove garlic peeled c seasoned dry bread crumbs and crushed tb butter or margarine melted\n",
            "= remove clams from half shell and chop coarsely set clams and shells aside in a mediumsized heatresistant nonmetallic mixing bowl place tablespoons butter heat in microwave oven seconds or until melted add onion and garlic heat uncovered in microwave oven energy minutes or until onion is tender add egg the cup bread crumbs chopped clams and oregano to onion mixture spoon mixture into reserved shells place shells on a heat resistant nonmetallic serving platter in a small bowl combine the cup seasoned bread crumbs and the tablespoons melted butter sprinkle buttered bread crumbs on top of clam mixture heat uncovered in microwave oven minutes or until heated through\n",
            "< preheat oven to degrees f grease a x baking dish mix together the flour salt and pepper in a large bowl mix the flour with the baking powder salt and pepper add the remaining ingredients mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each addition stir in the flour mixture and mix well add the milk and mix well add the eggs one at a time beating well after each\n",
            "BLEU: 4.554579973613856e-232\n",
            "\n",
            "> sauteed okra tomatoes corn lb okra stems and tips tb unsalted butter removed tb safflower oil lb tomatoes skinned and seeded c onions coarsely chopped ears fresh corn tb salt or to taste or freshly ground pepper c frozen corn kernels\n",
            "= cut okra into rounds discarding tops put tomatoes in stainless or enameled pan and cook slowly for half an hour drain any liquid cut corn from cob with sharp knife or defrost frozen corn heat butter and oil in a skillet add okra and onions cook until onions are wilted and okra has begun to brown at edges minutes turn often add reduced tomatoes and salt and cook minutes add corn and cook minutes season to taste\n",
            "< heat the oil in a large skillet over mediumhigh heat add the onion and saute until the onion is translucent add the onion and saute until the onions are translucent add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until the onions are tender add the onion and cook until\n",
            "BLEU: 6.441148769597431e-232\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder = EncoderRNN(input_lang.n_words, hidden_size)\n",
        "decoder = DecoderRNN(hidden_size, output_lang.n_words)\n",
        "encoder.load_state_dict(torch.load(\"Checkpoints/Vanilla/encoder35000\"))\n",
        "decoder.load_state_dict(torch.load(\"Checkpoints/Vanilla/decoder35000\"))\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "testing_pairs = extract_pairs(\"Dataset/test.tsv\")\n",
        "\n",
        "def evaluateModel1(encoder, decoder, data, n):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(data)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words= evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        overlap = calculate_metrics(pair[0], prediction=output_sentence)\n",
        "        print('<', output_sentence)\n",
        "        print(\"BLEU: {}\".format(overlap))\n",
        "        print('')\n",
        "\n",
        "def calculate_metrics(ground_truth, prediction):\n",
        "    ref_tokens = ground_truth.split()\n",
        "    ref_tokens = [ref_tokens]\n",
        "    candidate_tokens = prediction.split()\n",
        "    #TODO: implement METEOR, %Rec, %Spare\n",
        "    bleu = sentence_bleu(ref_tokens, candidate_tokens)\n",
        "    # meteor = \n",
        "    recall = ingredient_recall(ground_truth, prediction)\n",
        "    extra = extra_ingredients(ground_truth, prediction, input_lang) # TODO: pass in the ingredient lang here\n",
        "    # extra_ingredients = \n",
        "    return (bleu, recall, extra)\n",
        "\n",
        "#function to find the fraction of ingredients in the ground truth list which were included in the generated recipe\n",
        "def ingredient_recall(ground_truth, prediction):\n",
        "    recalled = 0\n",
        "    gt = ground_truth.split()\n",
        "    for i in gt:\n",
        "        if i in prediction:\n",
        "            recalled += 1\n",
        "    return recalled/len(gt)\n",
        "\n",
        "#function to find the fraction of ingredients which were wrongly generated (ie. not in the recipe specification)\n",
        "def extra_ingredients(ground_truth, prediction, ingredient_lang):\n",
        "    predicted_ingredients = [word for word in prediction.split() if ingredient_lang.contains(word)]\n",
        "    counting = 0\n",
        "    for ing in predicted_ingredients:\n",
        "        if ing not in ground_truth:\n",
        "            counting += 1\n",
        "    return counting/len(predicted_ingredients)\n",
        "        \n",
        "\n",
        "\n",
        "evaluateModel1(encoder, decoder, testing_pairs, n=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
